{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "78f95738-de9c-40af-9da3-fc6528404d9b",
   "metadata": {},
   "source": [
    "## Imports and Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "f0342b00-cdf5-4c07-af96-2aee7261d7aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import json\n",
    "from pathlib import Path\n",
    "import pandas as pd # For potential table handling later\n",
    "from markdown_it import MarkdownIt # For Markdown parsing\n",
    "\n",
    "# --- Configuration ---\n",
    "BASE_OUTPUT_DIR = Path(\"/Users/josephndigiovanni/Downloads/UChicago/SP24/Capstone 1/outputs\")\n",
    "JSON_OUTPUT_SUBDIR = \"hybrid_json_outputs\"\n",
    "JSON_OUTPUT_DIR = BASE_OUTPUT_DIR / JSON_OUTPUT_SUBDIR\n",
    "JSON_OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# --- Utility Functions ---\n",
    "\n",
    "def find_contract_files(base_dir):\n",
    "    \"\"\"\n",
    "    Finds all .md contract files within '...(Contract)' subdirectories.\n",
    "    Yields Path objects to the .md files.\n",
    "    \"\"\"\n",
    "    print(f\"Searching for contract folders in: {base_dir.resolve()}\")\n",
    "    found_any = False\n",
    "    for item in base_dir.iterdir():\n",
    "        if item.is_dir() and '(Contract)' in item.name:\n",
    "            contract_folder = item\n",
    "            md_files = list(contract_folder.glob('*.md'))\n",
    "            if md_files:\n",
    "                if len(md_files) > 1:\n",
    "                    print(f\"  Warning: Multiple .md files in {contract_folder.name}. Using first: {md_files[0].name}\")\n",
    "                yield md_files[0] # Yield the first .md file found\n",
    "                found_any = True\n",
    "            else:\n",
    "                print(f\"  Warning: No .md file found in {contract_folder.name}\")\n",
    "    if not found_any:\n",
    "        print(\"  No contract folders with .md files found.\")\n",
    "\n",
    "def read_markdown_file(md_filepath):\n",
    "    \"\"\"Reads content from a markdown file.\"\"\"\n",
    "    try:\n",
    "        with open(md_filepath, 'r', encoding='utf-8') as f:\n",
    "            content = f.read()\n",
    "        print(f\"  Successfully read {len(content)} characters from {md_filepath.name}.\")\n",
    "        return content\n",
    "    except Exception as e:\n",
    "        print(f\"  Error reading file {md_filepath.name}: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "cc3ee5f5-20df-4708-bb5c-213b15328956",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dateutil.parser import parse as parse_date_flexible\n",
    "from dateutil.relativedelta import relativedelta\n",
    "\n",
    "def normalize_date_robust(date_str):\n",
    "    \"\"\"Attempts to parse a date string into YYYY-MM-DD, handles more cases.\"\"\"\n",
    "    if not date_str or not isinstance(date_str, str):\n",
    "        return None\n",
    "    try:\n",
    "        date_str_cleaned = re.sub(r\"(\\d+)(?:st|nd|rd|th)\\s+day\\s+of\\s+\", \"\", date_str, flags=re.IGNORECASE)\n",
    "        dt = parse_date_flexible(date_str_cleaned)\n",
    "        return dt.strftime('%Y-%m-%d')\n",
    "    except (ValueError, TypeError, OverflowError) as e:\n",
    "        print(f\"    Debug: normalize_date_robust failed for '{date_str}': {e}\")\n",
    "        return None\n",
    "\n",
    "def calculate_end_date_from_term(start_date_str, months_str):\n",
    "    \"\"\"Calculates end date from start date and term in months.\"\"\"\n",
    "    if not start_date_str or not months_str:\n",
    "        return None\n",
    "    try:\n",
    "        start_date = parse_date_flexible(start_date_str)\n",
    "        months = int(months_str)\n",
    "        end_date = start_date + relativedelta(months=months) - relativedelta(days=1) \n",
    "        return end_date.strftime('%Y-%m-%d')\n",
    "    except (ValueError, TypeError):\n",
    "        return None\n",
    "\n",
    "# --- New Extraction Function ---\n",
    "def extract_contract_duration(sections, tables, contract_data_dict):\n",
    "    \"\"\"\n",
    "    Extracts contract start and end dates.\n",
    "    Populates contract_data_dict['contract_duration'] and contract_data_dict['_notes'].\n",
    "    \"\"\"\n",
    "    notes = contract_data_dict.get(\"_notes\", [])\n",
    "    start_date = None\n",
    "    end_date = None\n",
    "    term_months_val = None\n",
    "\n",
    "    # --- Define Search Space ---\n",
    "    # Prioritize specific sections if they exist, otherwise search all section content\n",
    "    search_texts = []    \n",
    "    term_section_keys = [k for k in sections if \"term\" in k.lower() and \"termination\" not in k.lower()] # Avoid \"Early Termination\"\n",
    "    delivery_period_keys = [k for k in sections if \"delivery period\" in k.lower()]\n",
    "    contract_info_keys = [k for k in sections if \"contract information\" in k.lower()]\n",
    "    \n",
    "    if delivery_period_keys:\n",
    "        search_texts.append(sections[delivery_period_keys[0]])\n",
    "        print(f\"  Duration: Searching in '{delivery_period_keys[0]}' section.\")\n",
    "    if term_section_keys:\n",
    "        search_texts.append(sections[term_section_keys[0]])\n",
    "        print(f\"  Duration: Searching in '{term_section_keys[0]}' section.\")\n",
    "    if contract_info_keys:\n",
    "        search_texts.append(sections[contract_info_keys[0]])\n",
    "        print(f\"  Duration: Searching in '{contract_info_keys[0]}' section.\")\n",
    "    \n",
    "    # Fallback to searching all section content if specific sections aren't found or don't yield results\n",
    "    if not search_texts:\n",
    "        print(\"  Duration: No specific duration sections found, searching all section content.\")\n",
    "        search_texts.extend(sections.values()) # Search text of all sections\n",
    "\n",
    "    # Regex for dates\n",
    "    date_val_pattern = r\"([\\w\\s,]+\\d{1,2}[,\\s]+(?:19|20)\\d{2}|\\d{1,2}[-/]\\d{1,2}[-/](?:19|20)?\\d{2})\"\n",
    "    # date_val_pattern matches: \"Month Day, Year\", \"Day Month, Year\", \"MM/DD/YYYY\", \"MM-DD-YY\", etc.\n",
    "\n",
    "    start_patterns = [\n",
    "        re.compile(rf\"Begin\\s*[:*]*\\s*{date_val_pattern}\", re.IGNORECASE),\n",
    "        re.compile(rf\"Start Date\\s*[:*]*\\s*{date_val_pattern}\", re.IGNORECASE),\n",
    "        re.compile(rf\"Effective\\s*(?:the date of this contract or date of first gas deliveries available thereafter)?\\s*(?:for|on)?\\s*{date_val_pattern}\", re.IGNORECASE), # Example 1 \"effective the date...\"\n",
    "    ]\n",
    "    end_patterns = [\n",
    "        re.compile(rf\"End\\s*[:*]*\\s*{date_val_pattern}\", re.IGNORECASE),\n",
    "        re.compile(rf\"End Date\\s*[:*]*\\s*{date_val_pattern}\", re.IGNORECASE),\n",
    "    ]\n",
    "    term_patterns = [\n",
    "        re.compile(r\"for\\s+(\\d+)\\s+months\", re.IGNORECASE), # Example 1 \"for 36 months\"\n",
    "        re.compile(r\"Term.*?for\\s+(\\d+)\\s+months\", re.IGNORECASE | re.DOTALL),\n",
    "    ]\n",
    "    executed_date_pattern = re.compile(rf\"Executed this\\s+{date_val_pattern}\", re.IGNORECASE) # Example 1\n",
    "\n",
    "    # --- Extraction Logic ---\n",
    "    for text_block in search_texts:\n",
    "        if not start_date:\n",
    "            for pattern in start_patterns:\n",
    "                match = pattern.search(text_block)\n",
    "                if match:\n",
    "                    start_date = normalize_date_robust(match.group(1)) # Group 1 is date_val_pattern\n",
    "                    if start_date: break \n",
    "            if start_date: print(f\"    Start Date found: {start_date}\")\n",
    "        \n",
    "        if not end_date:\n",
    "            for pattern in end_patterns:\n",
    "                match = pattern.search(text_block)\n",
    "                if match:\n",
    "                    end_date = normalize_date_robust(match.group(1))\n",
    "                    if end_date: break\n",
    "            if end_date: print(f\"    End Date found: {end_date}\")\n",
    "\n",
    "        if not term_months_val: # Only look for term if end_date isn't directly found\n",
    "            for pattern in term_patterns:\n",
    "                match = pattern.search(text_block)\n",
    "                if match:\n",
    "                    term_months_val = match.group(1)\n",
    "                    if term_months_val: break\n",
    "            if term_months_val: print(f\"    Term (months) found: {term_months_val}\")\n",
    "        \n",
    "        if start_date and end_date: # Stop if both found\n",
    "            break\n",
    "    \n",
    "    if not start_date:\n",
    "        for text_block in search_texts: # Re-search if not found in primary search\n",
    "            match = executed_date_pattern.search(text_block)\n",
    "            if match:\n",
    "                start_date = normalize_date_robust(match.group(1))\n",
    "                if start_date:\n",
    "                    print(f\"    Start Date (from Executed this): {start_date}\")\n",
    "                    break\n",
    "    \n",
    "    # Calculate end_date if start_date and term_months are found but no end_date\n",
    "    if start_date and term_months_val and not end_date:\n",
    "        end_date = calculate_end_date_from_term(start_date, term_months_val)\n",
    "        if end_date:\n",
    "            print(f\"    End Date (calculated from term): {end_date}\")\n",
    "            notes.append(f\"End date calculated from {term_months_val}-month term.\")\n",
    "        else:\n",
    "            notes.append(f\"Found start date and term ({term_months_val} months), but failed to calculate end date.\")\n",
    "\n",
    "    # Update contract_data_dict\n",
    "    contract_data_dict['contract_duration']['start_date'] = start_date\n",
    "    contract_data_dict['contract_duration']['end_date'] = end_date\n",
    "\n",
    "    if not start_date and not end_date and not term_months_val:\n",
    "        notes.append(\"Contract duration (start, end, or term) not found.\")\n",
    "        print(\"    Contract duration details not found.\")\n",
    "    elif not start_date:\n",
    "        notes.append(\"Contract start date not found.\")\n",
    "    elif not end_date:\n",
    "        notes.append(\"Contract end date (or term to calculate it) not found.\")\n",
    "\n",
    "    contract_data_dict['_notes'] = notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "7c13edf9-a6bc-4e38-83cc-98a9374a8540",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import calendar \n",
    "from collections import defaultdict\n",
    "\n",
    "# This is the _process_rate_match that corresponds to the single rate_pattern_general\n",
    "# which previously worked for Ex2 and Ex4.\n",
    "def _process_single_general_match(match, contract_data_dict, rates_list_ref, primary_unit_ref_list):\n",
    "    notes = contract_data_dict.get(\"_notes\", [])\n",
    "    section_name_for_debug = contract_data_dict.get(\"_current_section_name_debug\", \"Unknown Section\")\n",
    "\n",
    "    # --- ENABLE THIS DEBUG BLOCK ---\n",
    "    is_target_debug_line = False\n",
    "    contract_id = contract_data_dict.get(\"contract_id\", \"\")\n",
    "    line_text_for_debug = match.group(0).strip()\n",
    "\n",
    "    if \"Example 1 (Contract)\" in contract_id and (\"Tier One\" in line_text_for_debug or \"Tier Two\" in line_text_for_debug):\n",
    "        is_target_debug_line = True\n",
    "    elif \"Example 2 (Contract)\" in contract_id and \"Contract price ($/kwh):** 0.09623\" in line_text_for_debug :\n",
    "         is_target_debug_line = True\n",
    "\n",
    "\n",
    "    if is_target_debug_line: \n",
    "        print(f\"\\nDEBUG HELPER MATCH (Target Contract/Section: '{contract_id}'/'{section_name_for_debug}'):\")\n",
    "        print(f\"  Line Matched by Regex: '{line_text_for_debug}'\")\n",
    "        print(f\"  Iterating over groups for this match:\")\n",
    "        for group_name_val_key in match.re.groupindex.keys():\n",
    "            try:\n",
    "                group_content = match.group(group_name_val_key)\n",
    "                print(f\"    Group ({group_name_val_key}): '{group_content}'\")\n",
    "            except IndexError: \n",
    "                print(f\"    Group ({group_name_val_key}): DID NOT PARTICIPATE\") \n",
    "        print(\"--- End of Groups for this Match ---\")\n",
    "    # --- END DEBUG ---\n",
    "\n",
    "    rate_value_str = match.group(\"value\").replace(',', '').strip()\n",
    "    if not rate_value_str: \n",
    "        return False \n",
    "\n",
    "    tier_name = None\n",
    "    if match.group(\"tier_prefix\"): # No need for \"in match.re.groupindex\" if group is always defined\n",
    "        tier_match_extract = re.search(r\"Tier\\s+\\w+\", match.group(\"tier_prefix\"), re.IGNORECASE)\n",
    "        if tier_match_extract:\n",
    "            tier_name = tier_match_extract.group(0).strip()\n",
    "\n",
    "    actual_label = None\n",
    "    if match.group(\"label\"): # \"label\" is the named group for (Fixed Price|Contract price|Index Price)\n",
    "        label_from_group = match.group(\"label\") # This group itself doesn't have the stars\n",
    "        actual_label = label_from_group.strip() # The surrounding \\*{0,2} handle stars\n",
    "\n",
    "    current_rate_unit = None\n",
    "    current_currency = None\n",
    "\n",
    "    if match.group(\"unit_in_label\"):\n",
    "        current_rate_unit = match.group(\"unit_in_label\").upper()\n",
    "        if match.group(\"currency_in_label\"):\n",
    "            current_currency = match.group(\"currency_in_label\")\n",
    "    elif match.group(\"unit_after_value\"):\n",
    "        current_rate_unit = match.group(\"unit_after_value\").upper()\n",
    "    elif match.group(\"unit_val_in_paren\"): \n",
    "        current_rate_unit = match.group(\"unit_val_in_paren\").upper()\n",
    "\n",
    "    if not current_currency and match.group(\"currency_before_value\"):\n",
    "        current_currency = match.group(\"currency_before_value\")\n",
    "    \n",
    "    if not current_currency: current_currency = '$' \n",
    "\n",
    "    if not current_rate_unit:\n",
    "        # This should only print if a value was found but absolutely no unit could be derived from any group\n",
    "        print(f\"    Rate value '{rate_value_str}' found, but unit not parsed. Line: '{match.group(0).strip()}'. Desc: '{match.group('description_before_math')}' Skipping.\")\n",
    "        notes.append(f\"Rate value '{rate_value_str}' (Sec: '{section_name_for_debug}') no unit; skipped.\")\n",
    "        return False\n",
    "\n",
    "    std_unit = current_rate_unit\n",
    "    if current_rate_unit == \"DTHS\": std_unit = \"DTH\"\n",
    "    elif current_rate_unit == \"MMBTUS\": std_unit = \"MMBTU\"\n",
    "    elif current_rate_unit == \"KWH\": std_unit = \"KWH\" \n",
    "    elif current_rate_unit == \"THERMS\": std_unit = \"THERM\"\n",
    "    current_rate_unit = std_unit\n",
    "\n",
    "    try:\n",
    "        rate_value_float = float(rate_value_str)\n",
    "        rate_display_unit = f\"{current_currency}/{current_rate_unit}\"\n",
    "\n",
    "        if current_currency == '¢':\n",
    "            rate_value_float /= 100.0\n",
    "            rate_display_unit = f\"$/{current_rate_unit}\"\n",
    "        \n",
    "        rate_entry = {\n",
    "            \"rate\": f\"{rate_value_float:.5f}\" if current_currency == '¢' else str(rate_value_float),\n",
    "            \"unit_full_string\": rate_display_unit,\n",
    "            \"base_unit\": current_rate_unit,\n",
    "            \"label_matched\": actual_label \n",
    "        }\n",
    "        desc_text = match.group(\"description_before_math\")\n",
    "        math_op = match.group(\"math_operator\")\n",
    "        if desc_text and desc_text.strip() and desc_text.strip() != \"**\": # Avoid storing just \"**\"\n",
    "            rate_entry[\"index_description\"] = desc_text.strip()\n",
    "        if math_op: \n",
    "            rate_entry[\"index_operator\"] = math_op\n",
    "        \n",
    "        if tier_name: rate_entry[\"tier\"] = tier_name\n",
    "        \n",
    "        is_duplicate_entry = any(\n",
    "            ex_rate.get(\"tier\") == rate_entry.get(\"tier\") and \\\n",
    "            ex_rate.get(\"base_unit\") == rate_entry.get(\"base_unit\") and \\\n",
    "            abs(float(ex_rate.get(\"rate\", 0)) - float(rate_entry.get(\"rate\", -1))) < 0.00001\n",
    "            for ex_rate in rates_list_ref\n",
    "        )\n",
    "        \n",
    "        if not is_duplicate_entry:\n",
    "            rates_list_ref.append(rate_entry)\n",
    "            print(f\"    Found Rate (single_general_pattern): {(tier_name + ': ') if tier_name else ''}{rate_entry['rate']} {rate_entry['unit_full_string']}\")\n",
    "            if not primary_unit_ref_list[0]: \n",
    "                primary_unit_ref_list[0] = current_rate_unit\n",
    "            return True \n",
    "    except ValueError:\n",
    "        notes.append(f\"Could not parse rate value '{rate_value_str}' for unit '{current_rate_unit}'.\")\n",
    "        print(f\"    Warning: Could not parse rate value '{rate_value_str}' from: {match.group(0).strip()}\")\n",
    "    except Exception as e:\n",
    "        print(f\"    Error processing rate (single_general_pattern): {e} from: {match.group(0).strip()}\")\n",
    "    return False\n",
    "\n",
    "\n",
    "def extract_rates_and_unit(sections, tables, contract_data_dict, markdown_content_for_fallback=\"\"):\n",
    "    notes = contract_data_dict.get(\"_notes\", [])\n",
    "    rates = []\n",
    "    primary_unit_mutable = [None] \n",
    "\n",
    "    # --- Search Space Logic (Keep the refined version) ---\n",
    "    search_sources_for_rates = [] \n",
    "    sections_to_search_map = {}\n",
    "    ordered_section_keywords = [\"contract price\", \"purchase price\", \"pricing\", \"rate\"] \n",
    "\n",
    "    for keyword in ordered_section_keywords:\n",
    "        for section_name, section_content in sections.items():\n",
    "            if keyword in section_name.lower():\n",
    "                if section_name not in sections_to_search_map:\n",
    "                    sections_to_search_map[section_name] = section_content\n",
    "    \n",
    "    if not sections_to_search_map or not any(kw in name.lower() for name in sections_to_search_map for kw in [\"contract price\", \"purchase price\"]):\n",
    "        for section_name, section_content in sections.items():\n",
    "            if section_name not in sections_to_search_map: \n",
    "                if any(key_term in section_content.lower() for key_term in [\"price is\", \"price:\", \" rate:\", \"fixed at\", \"$/\", \"¢/\", \" per \"]):\n",
    "                    if section_name not in sections_to_search_map:\n",
    "                        sections_to_search_map[section_name] = section_content\n",
    "    \n",
    "    if sections_to_search_map:\n",
    "        for name, content in sections_to_search_map.items():\n",
    "            search_sources_for_rates.append((name, content))\n",
    "            print(f\"  Rates: Using section '{name}' for rates search.\") # Added print\n",
    "    elif sections: \n",
    "        print(\"  Rates: No specific sections by name/content, using all sections.\")\n",
    "        for name, content in sections.items():\n",
    "            search_sources_for_rates.append((name, content))\n",
    "    elif markdown_content_for_fallback:\n",
    "         search_sources_for_rates.append((\"full_document_fallback\", markdown_content_for_fallback))\n",
    "    else: \n",
    "         print(\"  Rates: No section content to search.\")\n",
    "\n",
    "\n",
    "    # --- Regex Patterns (Reverted to the single general pattern that worked for Ex2 & Ex4) ---\n",
    "    rate_pattern_general = re.compile(\n",
    "        r\"^(?:[\\s\\-*]*)\"\n",
    "        r\"(?P<tier_prefix>(?:\\*{0,2}Tier\\s+\\w+\\*{0,2}\\s*:\\s*)?)\" \n",
    "        r\"\\*{0,2}(?P<label>Fixed Price|Contract price|Index Price)\\*{0,2}\" \n",
    "        r\"\\s*(?:\\((?P<currency_in_label>[\\$¢])?\\s*/\\s*(?P<unit_in_label>\\w+)\\))?\" \n",
    "        r\"\\*{0,2}\\s*[:\\-]\\s*\" \n",
    "        r\"(?P<description_before_math>.*?)\" \n",
    "        r\"(?P<math_operator>[+\\-])?\\s*\"\n",
    "        r\"(?P<currency_before_value>[\\$¢])?\" \n",
    "        r\"\\s*(?P<value>[\\d.,]+)\" \n",
    "        r\"(?:\\s*(?:per|/)\\s*(?P<unit_after_value>KWh|MMBTU|Dth|Therm)\\b)?\"\n",
    "        r\"(?:\\s*\\((?P<unit_val_in_paren>\\w+)\\)\\s*)?\", \n",
    "        re.IGNORECASE\n",
    "    )\n",
    "    \n",
    "    cents_rate_pattern = re.compile(\n",
    "        r\"^(?:[\\s\\-*]*)\" \n",
    "        r\"(?P<value>[\\d.,]+)\\s+(?:¢|cents)\\s*(?:per|/)\\s*(?P<unit>KWh|MMBTU|Dth|Therm)\\b\",\n",
    "        re.IGNORECASE \n",
    "    )\n",
    "    \n",
    "    unit_context_pattern = re.compile( # This is fine for broader searches\n",
    "        r\"(?:Volume|Quantity)\\s+(?:per\\s+Month\\s+)?in\\s+(?P<unit>Dths|MMBTUs|kWh|Therms)\\b\",\n",
    "        re.IGNORECASE\n",
    "    )\n",
    "\n",
    "    globally_processed_rate_lines = set() \n",
    "\n",
    "    for section_name_for_debug, text_block_original in search_sources_for_rates:\n",
    "        text_block_stripped = text_block_original.strip() \n",
    "        contract_data_dict['_current_section_name_debug'] = section_name_for_debug\n",
    "\n",
    "        # --- DEBUG PRINT FOR SECTION BEING PROCESSED FOR EX1 ---\n",
    "        if \"Example 1 (Contract)\" in contract_data_dict.get(\"contract_id\", \"\") and \\\n",
    "           (\"Contract Price\" in section_name_for_debug if section_name_for_debug else False):\n",
    "            print(f\"\\n[EX1 DEBUG] Processing Section '{section_name_for_debug}' line by line for rates.\")\n",
    "            # print(f\"  Content sample: '{text_block_stripped[:300]}...'\") # Optional\n",
    "\n",
    "        for line_count, line in enumerate(text_block_stripped.splitlines()):\n",
    "            line = line.strip() \n",
    "            if not line or line in globally_processed_rate_lines:\n",
    "                continue\n",
    "            \n",
    "            # --- DEBUG PRINT FOR EACH LINE FOR EX1 ---\n",
    "            if \"Example 1 (Contract)\" in contract_data_dict.get(\"contract_id\", \"\") and \\\n",
    "               (\"Contract Price\" in section_name_for_debug if section_name_for_debug else False):\n",
    "                print(f\"  [EX1 L{line_count+1}] Attempting match on: '{line}'\")\n",
    "            # ---\n",
    "\n",
    "            match_general = rate_pattern_general.search(line) \n",
    "            if match_general:\n",
    "                if _process_single_general_match(match_general, contract_data_dict, rates, primary_unit_mutable):\n",
    "                    globally_processed_rate_lines.add(line)\n",
    "                    continue \n",
    "\n",
    "            if line not in globally_processed_rate_lines:\n",
    "                match_cents = cents_rate_pattern.search(line)\n",
    "                if match_cents:\n",
    "                    rate_value_str_cents = match_cents.group(\"value\").replace(',', '').strip()\n",
    "                    unit_cents = match_cents.group(\"unit\").upper()\n",
    "                    std_unit_cents = unit_cents\n",
    "                    if unit_cents == \"DTHS\": std_unit_cents = \"DTH\"\n",
    "\n",
    "                    try:\n",
    "                        rate_value_cents_float = float(rate_value_str_cents)\n",
    "                        rate_value_dollars = rate_value_cents_float / 100.0\n",
    "                        rate_entry = {\n",
    "                            \"rate\": f\"{rate_value_dollars:.5f}\",\n",
    "                            \"unit_full_string\": f\"$/{std_unit_cents}\",\n",
    "                            \"base_unit\": std_unit_cents\n",
    "                        }\n",
    "                        is_duplicate = any(\n",
    "                            r_existing[\"base_unit\"] == std_unit_cents and \\\n",
    "                            abs(float(r_existing[\"rate\"]) - rate_value_dollars) < 0.00001 \n",
    "                            for r_existing in rates\n",
    "                        )\n",
    "                        if not is_duplicate:\n",
    "                            rates.append(rate_entry)\n",
    "                            print(f\"    Found Cents Rate: {rate_value_cents_float} cents/{std_unit_cents} -> {rate_entry['rate']} {rate_entry['unit_full_string']}\")\n",
    "                            if not primary_unit_mutable[0]: primary_unit_mutable[0] = std_unit_cents\n",
    "                            globally_processed_rate_lines.add(line)\n",
    "                    except ValueError:\n",
    "                        notes.append(f\"Could not parse cents rate '{rate_value_str_cents}'.\")\n",
    "\n",
    "    primary_unit = primary_unit_mutable[0] \n",
    "    # --- Infer Primary Unit (logic remains same) ---\n",
    "    if not primary_unit:\n",
    "        all_text_for_unit_context = \" \".join(s[1] for s in search_sources_for_rates) if search_sources_for_rates else markdown_content_for_fallback\n",
    "        context_match = unit_context_pattern.search(all_text_for_unit_context)\n",
    "        if context_match:\n",
    "            unit_from_context = context_match.group(\"unit\").upper()\n",
    "            if unit_from_context in [\"DTHS\", \"DTH\"]: primary_unit = \"DTH\"\n",
    "            elif unit_from_context == \"MMBTUS\": primary_unit = \"MMBTU\"\n",
    "            elif unit_from_context == \"KWH\": primary_unit = \"KWH\"\n",
    "            elif unit_from_context == \"THERMS\": primary_unit = \"THERM\"\n",
    "            if primary_unit:\n",
    "                notes.append(f\"Primary UoM '{primary_unit}' inferred from document context.\")\n",
    "                # print(f\"    Inferred Primary UoM from context: {primary_unit}\")\n",
    "\n",
    "    if not primary_unit:\n",
    "        all_text_content = (\" \".join(s[1] for s in search_sources_for_rates) if search_sources_for_rates else markdown_content_for_fallback).upper()\n",
    "        if \"ELECTRIC\" in all_text_content: primary_unit = \"KWH\"; notes.append(\"UoM 'KWH' from 'ELECTRIC' keyword.\")\n",
    "        elif \"GAS\" in all_text_content: primary_unit = \"MMBTU\"; notes.append(\"UoM 'MMBTU' from 'GAS' keyword.\")\n",
    "        # if primary_unit: print(f\"    Inferred Primary UoM by keyword: {primary_unit}\")\n",
    "    \n",
    "    if not rates:\n",
    "        notes.append(\"No contracted rate information found.\")\n",
    "        print(f\"  Rates: Warning: No contracted rates found for {contract_data_dict.get('contract_id')}.\")\n",
    "    \n",
    "    contract_data_dict['contracted_rates'] = rates\n",
    "    contract_data_dict['unit_of_measurement'] = primary_unit\n",
    "    contract_data_dict['_notes'] = notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "058c5869-f63d-45ca-a612-f0a342c01c64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Desc: ''\n",
      "Operator: 'None'\n",
      "Currency: '$'\n",
      "Value: '4.40'\n",
      "Unit: 'Dth'\n",
      "\n",
      "Index Line:\n",
      "Desc: ' Gas Market Report - Colorado Interstate Gas '\n",
      "Operator: '+'\n",
      "Currency: '$'\n",
      "Value: '.99'\n",
      "Unit: 'Dth'\n"
     ]
    }
   ],
   "source": [
    "# debugging for ex1\n",
    "\n",
    "import re\n",
    "line = \"- **Tier One:** Fixed Price: $4.40 per Dth\"\n",
    "pattern_segment = re.compile(\n",
    "    r\"(?P<description_before_math>.*?)\"              # F\n",
    "    r\"(?P<math_operator>[+\\-])?\\s*\"                  # G\n",
    "    r\"(?P<currency_before_value>[\\$¢])?\"             # H\n",
    "    r\"\\s*(?P<value>[\\d.,]+)\"                         # I\n",
    "    r\"(?:\\s*(?:per|/)\\s*(?P<unit_after_value>KWh|MMBTU|Dth|Therm)\\b)?\", # J\n",
    "    re.IGNORECASE\n",
    ")\n",
    "remaining_text = \" $4.40 per Dth\" \n",
    "m = pattern_segment.match(remaining_text) \n",
    "if m:\n",
    "    print(f\"Desc: '{m.group('description_before_math')}'\")\n",
    "    print(f\"Operator: '{m.group('math_operator')}'\")\n",
    "    print(f\"Currency: '{m.group('currency_before_value')}'\")\n",
    "    print(f\"Value: '{m.group('value')}'\")\n",
    "    print(f\"Unit: '{m.group('unit_after_value')}'\")\n",
    "else:\n",
    "    print(\"Segment did not match\")\n",
    "\n",
    "# For the Index Price line:\n",
    "remaining_text_index = \" Gas Market Report - Colorado Interstate Gas + $.99 per Dth\"\n",
    "m_index = pattern_segment.match(remaining_text_index)\n",
    "if m_index:\n",
    "    print(\"\\nIndex Line:\")\n",
    "    print(f\"Desc: '{m_index.group('description_before_math')}'\")\n",
    "    print(f\"Operator: '{m_index.group('math_operator')}'\")\n",
    "    print(f\"Currency: '{m_index.group('currency_before_value')}'\")\n",
    "    print(f\"Value: '{m_index.group('value')}'\")\n",
    "    print(f\"Unit: '{m_index.group('unit_after_value')}'\")\n",
    "else:\n",
    "    print(\"Index segment did not match\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "id": "204fab02-35ba-4518-9492-90ec329ea465",
   "metadata": {},
   "outputs": [],
   "source": [
    "import calendar # Ensure this is at the top\n",
    "from dateutil.parser import parse as parse_date_flexible # Already should be there\n",
    "from dateutil.relativedelta import relativedelta # Already should be there\n",
    "\n",
    "def generate_full_yyyymm_sequence(start_date_str, end_date_str):\n",
    "    \"\"\"Generates a list of 'YYYY-MM' strings for the contract duration.\"\"\"\n",
    "    if not start_date_str or not end_date_str:\n",
    "        return []\n",
    "    \n",
    "    try:\n",
    "        start_dt = parse_date_flexible(start_date_str)\n",
    "        end_dt = parse_date_flexible(end_date_str)\n",
    "        \n",
    "        yyyymm_list = []\n",
    "        current_dt = start_dt\n",
    "        while current_dt <= end_dt:\n",
    "            yyyymm_list.append(current_dt.strftime('%Y-%m'))\n",
    "            current_dt += relativedelta(months=1)\n",
    "        return yyyymm_list\n",
    "    except Exception as e:\n",
    "        print(f\"    Warning: Could not generate YYYY-MM sequence from {start_date_str} to {end_date_str}: {e}\")\n",
    "        return []\n",
    "\n",
    "def map_month_name_to_int(month_name_str):\n",
    "    \"\"\"Maps month name (Jan, January, etc.) to month number (1-12).\"\"\"\n",
    "    if not month_name_str or not isinstance(month_name_str, str):\n",
    "        return None\n",
    "    try:\n",
    "        # Try parsing with dateutil first (flexible)\n",
    "        return parse_date_flexible(month_name_str).month\n",
    "    except ValueError:\n",
    "        # Fallback for short names if parser fails\n",
    "        month_name_lower_abbr = month_name_str.strip().lower()[:3]\n",
    "        month_map = {name.lower(): num for num, name in enumerate(calendar.month_abbr) if num > 0}\n",
    "        return month_map.get(month_name_lower_abbr)\n",
    "\n",
    "\n",
    "def extract_monthly_usage(sections, tables, contract_data_dict):\n",
    "    \"\"\"\n",
    "    Extracts monthly forecasted usage from tables.\n",
    "    Populates contract_data_dict['monthly_forecasted_usage'].\n",
    "    \"\"\"\n",
    "    notes = contract_data_dict.get(\"_notes\", [])\n",
    "    forecast_usage = {} # YYYY-MM: value\n",
    "\n",
    "    contract_start_date = contract_data_dict.get('contract_duration', {}).get('start_date')\n",
    "    contract_end_date = contract_data_dict.get('contract_duration', {}).get('end_date')\n",
    "\n",
    "    if not contract_start_date or not contract_end_date:\n",
    "        notes.append(\"Cannot extract monthly usage without contract start/end dates for year assignment.\")\n",
    "        print(\"  Usage: Skipping monthly usage extraction - missing contract duration.\")\n",
    "        contract_data_dict['monthly_forecasted_usage'] = {} # Ensure it's an empty dict\n",
    "        contract_data_dict['_notes'] = notes\n",
    "        return\n",
    "\n",
    "    found_usage_table = False\n",
    "    raw_monthly_values = [] # List of (month_int, usage_value) tuples\n",
    "\n",
    "    for table_idx, df in enumerate(tables):\n",
    "        # Normalize column names for easier matching\n",
    "        print(f\"  Usage: Analyzing Table {table_idx} with columns: {df.columns.tolist()}\") # Debug table columns\n",
    "        \n",
    "        # Convert all column names to lower string, strip spaces, handle non-string cols\n",
    "        df_columns_normalized = {}\n",
    "        for col in df.columns:\n",
    "            try:\n",
    "                norm_col = str(col).lower().replace(' ', '').replace('_', '').replace('.', '')\n",
    "                df_columns_normalized[norm_col] = col # Map normalized to original\n",
    "            except: # Handle non-string column names if any by skipping them\n",
    "                pass\n",
    "\n",
    "        month_col_orig = None\n",
    "        usage_col_orig = None\n",
    "        \n",
    "        # Common month column names\n",
    "        month_col_candidates = ['month', 'mon']\n",
    "        for cand_norm in month_col_candidates:\n",
    "            if cand_norm in df_columns_normalized:\n",
    "                month_col_orig = df_columns_normalized[cand_norm]\n",
    "                break\n",
    "        \n",
    "        # Common usage/volume/quantity column names\n",
    "        usage_col_candidates = ['volume', 'quantity', 'monthlyquantity', 'usage', 'baseloadvolume']\n",
    "        for cand_norm in usage_col_candidates:\n",
    "            if cand_norm in df_columns_normalized:\n",
    "                usage_col_orig = df_columns_normalized[cand_norm]\n",
    "                break\n",
    "        \n",
    "        if month_col_orig and usage_col_orig:\n",
    "            print(f\"    Usage: Found potential usage table {table_idx} (Cols: '{month_col_orig}', '{usage_col_orig}')\")\n",
    "            found_usage_table = True\n",
    "            for _, row in df.iterrows():\n",
    "                try:\n",
    "                    month_name = str(row[month_col_orig])\n",
    "                    usage_val_str = str(row[usage_col_orig]).replace(',', '').strip()\n",
    "\n",
    "                    month_int = map_month_name_to_int(month_name)\n",
    "                    \n",
    "                    if month_int and usage_val_str and usage_val_str.isdigit():\n",
    "                        usage_val = int(usage_val_str)\n",
    "                        raw_monthly_values.append((month_int, usage_val))\n",
    "                        print(f\"      Raw usage added: Month {month_int}, Value {usage_val}\") # Debug\n",
    "                    else:\n",
    "                        print(f\"      Skipping row: Month='{month_name}' (Int: {month_int}), Usage='{usage_val_str}'\") # Debug\n",
    "                except KeyError:\n",
    "                    print(f\"      KeyError accessing row in table {table_idx}. Columns might be inconsistent.\")\n",
    "                    continue # Skip row if keys don't exist (e.g. malformed table)\n",
    "                except Exception as e:\n",
    "                    print(f\"      Error processing row in table {table_idx}: {e}\")\n",
    "                    continue\n",
    "            \n",
    "            if len(raw_monthly_values) >= 12: break # Optimization: if we have 12 months, assume it's the primary table\n",
    "    \n",
    "    if not found_usage_table:\n",
    "        notes.append(\"No table found with recognizable month and usage columns.\")\n",
    "        print(\"    Usage: No monthly usage table identified.\")\n",
    "    \n",
    "    if raw_monthly_values:\n",
    "        # Aggregate values if same month appears multiple times (e.g. from different tables/locations)\n",
    "        aggregated_raw_values = defaultdict(int)\n",
    "        for m_int, val in raw_monthly_values:\n",
    "            aggregated_raw_values[m_int] += val\n",
    "        \n",
    "        sorted_monthly_pattern = sorted(aggregated_raw_values.items()) \n",
    "        \n",
    "        if not sorted_monthly_pattern:\n",
    "            notes.append(\"Processed raw usage values but resulted in empty pattern.\")\n",
    "            print(\"    Usage: Aggregated raw usage values but pattern is empty.\")\n",
    "        else:\n",
    "            num_pattern_months = len(sorted_monthly_pattern)\n",
    "            print(f\"    Usage: Using a {num_pattern_months}-month usage pattern from table(s).\")\n",
    "            \n",
    "            all_contract_yyyymm = generate_full_yyyymm_sequence(contract_start_date, contract_end_date)\n",
    "            if not all_contract_yyyymm:\n",
    "                notes.append(\"Could not generate YYYY-MM sequence for usage assignment.\")\n",
    "                print(\"    Usage: Error generating YYYY-MM sequence for contract duration.\")\n",
    "            else:\n",
    "                for i, yyyymm in enumerate(all_contract_yyyymm):\n",
    "                    current_month_int = int(yyyymm.split('-')[1])\n",
    "                    \n",
    "                    # Find the value for this current_month_int from our pattern\n",
    "                    # This simple cyclical mapping assumes the table gives one year's pattern\n",
    "                    # If the table spans multiple years explicitly, this needs more advanced logic.\n",
    "                    \n",
    "                    # Option 1: Simple cyclical based on month number matching pattern\n",
    "                    value_for_month = 0\n",
    "                    for pat_month_int, pat_value in sorted_monthly_pattern:\n",
    "                        if pat_month_int == current_month_int:\n",
    "                            value_for_month = pat_value\n",
    "                            break\n",
    "                    forecast_usage[yyyymm] = value_for_month\n",
    "\n",
    "                    \n",
    "                    if num_pattern_months >= len(all_contract_yyyymm) and num_pattern_months > 0 : \n",
    "                        # Sticking to simpler cyclical pattern for now based on month number:\n",
    "                        value_for_month = 0\n",
    "                        pattern_idx_for_month = (current_month_int - 1) % num_pattern_months # Simple map to pattern\n",
    "                        # This above line is wrong if num_pattern_months != 12.\n",
    "                        # It should be: find 'current_month_int' in 'sorted_monthly_pattern'\n",
    "                        \n",
    "                        found_in_pattern = False\n",
    "                        for pat_m_int, pat_val in sorted_monthly_pattern:\n",
    "                            if pat_m_int == current_month_int:\n",
    "                                forecast_usage[yyyymm] = pat_val\n",
    "                                found_in_pattern = True\n",
    "                                break\n",
    "                        if not found_in_pattern and sorted_monthly_pattern: # Fallback if month not in pattern (e.g. 11 month pattern)\n",
    "                            # Use a default or first/last value from pattern, or 0\n",
    "                            forecast_usage[yyyymm] = sorted_monthly_pattern[i % num_pattern_months][1] if num_pattern_months > 0 else 0\n",
    "\n",
    "\n",
    "                    elif num_pattern_months > 0: # Standard cyclical application (e.g. 12 month pattern)\n",
    "                        value_for_current_month = 0\n",
    "                        for p_month, p_value in sorted_monthly_pattern:\n",
    "                            if p_month == current_month_int:\n",
    "                                value_for_current_month = p_value\n",
    "                                break\n",
    "                        forecast_usage[yyyymm] = sorted_monthly_pattern[i % num_pattern_months][1]\n",
    "\n",
    "                notes.append(f\"Applied {num_pattern_months}-month usage pattern over contract duration.\")\n",
    "                print(f\"    Usage: Assigned usage for {len(forecast_usage)} months.\")\n",
    "\n",
    "    if not forecast_usage: # If no table data, check for annual total as fallback\n",
    "        print(\"    Usage: No monthly table data. Checking for Annual Usage fallback.\")\n",
    "        annual_usage_val = None\n",
    "        annual_pattern = re.compile(r\"Annual\\s*(?:Historical\\s+)?Usage\\s*\\(?[A-Za-z\\s]*\\)?\\s*[:\\-]?\\s*([\\d,]+)\", re.IGNORECASE)\n",
    "        for section_content in sections.values():\n",
    "            match = annual_pattern.search(section_content)\n",
    "            if match:\n",
    "                try:\n",
    "                    annual_usage_val = int(match.group(1).replace(',', ''))\n",
    "                    print(f\"    Usage: Found Annual Usage: {annual_usage_val}\")\n",
    "                    break\n",
    "                except ValueError:\n",
    "                    pass\n",
    "        \n",
    "        if annual_usage_val is not None:\n",
    "            monthly_avg = round(annual_usage_val / 12)\n",
    "            all_contract_yyyymm = generate_full_yyyymm_sequence(contract_start_date, contract_end_date)\n",
    "            if all_contract_yyyymm:\n",
    "                for yyyymm in all_contract_yyyymm:\n",
    "                    forecast_usage[yyyymm] = monthly_avg\n",
    "                notes.append(f\"Applied annual usage, distributed as {monthly_avg}/month.\")\n",
    "                print(f\"    Usage: Distributed annual usage as {monthly_avg}/month for {len(forecast_usage)} months.\")\n",
    "            else:\n",
    "                notes.append(f\"Found annual usage {annual_usage_val} but could not distribute (no YYYY-MM sequence).\")\n",
    "\n",
    "\n",
    "    contract_data_dict['monthly_forecasted_usage'] = dict(sorted(forecast_usage.items())) # Sort by YYYY-MM\n",
    "    contract_data_dict['_notes'] = notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "id": "f341e135-8146-4fb1-99be-47ab1339d832",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (Ensure pandas as pd is imported at the top)\n",
    "\n",
    "def extract_service_account_details(sections, tables, contract_data_dict, markdown_content_for_fallback=\"\"):\n",
    "    notes = contract_data_dict.get(\"_notes\", [])\n",
    "    \n",
    "    service_addresses = set(contract_data_dict.get('service_addresses', [])) # Initialize from existing\n",
    "    account_numbers = set(contract_data_dict.get('account_numbers', []))\n",
    "    meter_numbers = set(contract_data_dict.get('meter_numbers', []))\n",
    "    \n",
    "    # Rate class can be a string or list, handle carefully\n",
    "    current_rate_class = contract_data_dict.get('rate_class')\n",
    "    if isinstance(current_rate_class, str):\n",
    "        rate_classes = {current_rate_class}\n",
    "    elif isinstance(current_rate_class, list):\n",
    "        rate_classes = set(current_rate_class)\n",
    "    else:\n",
    "        rate_classes = set()\n",
    "\n",
    "    # --- Table-Based Extraction ---\n",
    "    processed_tables_for_details = set() # To avoid processing same table multiple times if called again\n",
    "    for table_idx, df in enumerate(tables):\n",
    "        if table_idx in processed_tables_for_details:\n",
    "            continue\n",
    "        \n",
    "        df_columns_normalized = {str(col).lower().replace(' ', '').replace('_', '').replace('.', '').replace('/', '').replace('#',''): col for col in df.columns}\n",
    "        \n",
    "        addr_keys = ['serviceaddress', 'facilitynameserviceaddress', 'facilityaddress', 'address']\n",
    "        acc_keys = ['accountnumber', 'utilityaccountnumber', 'account'] # Removed '#' from key for now\n",
    "        meter_keys = ['meter', 'meternumber', 'deliverypoint'] # Removed '#'\n",
    "        rate_class_keys = ['rate', 'rateclass', 'ratecode']\n",
    "\n",
    "        addr_col_orig, acc_col_orig, meter_col_orig, rate_class_col_orig = None, None, None, None\n",
    "\n",
    "        for key in addr_keys:\n",
    "            if key in df_columns_normalized: addr_col_orig = df_columns_normalized[key]; break\n",
    "        for key in acc_keys:\n",
    "            if key in df_columns_normalized: acc_col_orig = df_columns_normalized[key]; break\n",
    "        for key in meter_keys: # Meter # is tricky due to '#'\n",
    "            if key in df_columns_normalized: meter_col_orig = df_columns_normalized[key]; break\n",
    "            # Specific check for \"Meter #\" column if normalization missed it\n",
    "            if not meter_col_orig:\n",
    "                for orig_col_name in df.columns:\n",
    "                    if str(orig_col_name).strip().lower() == \"meter #\":\n",
    "                        meter_col_orig = orig_col_name; break\n",
    "        for key in rate_class_keys:\n",
    "            if key in df_columns_normalized: rate_class_col_orig = df_columns_normalized[key]; break\n",
    "        \n",
    "        if sum(col is not None for col in [addr_col_orig, acc_col_orig, meter_col_orig, rate_class_col_orig]) >= 1:\n",
    "            print(f\"    Details: Processing Table {table_idx} for account/service info (Cols: A:{addr_col_orig}, Acct:{acc_col_orig}, M:{meter_col_orig}, RC:{rate_class_col_orig}).\")\n",
    "            processed_tables_for_details.add(table_idx)\n",
    "            for _, row in df.iterrows():\n",
    "                try:\n",
    "                    if addr_col_orig and pd.notna(row[addr_col_orig]):\n",
    "                        addr = str(row[addr_col_orig]).strip()\n",
    "                        if addr and len(addr) > 5: service_addresses.add(addr)\n",
    "                    \n",
    "                    if acc_col_orig and pd.notna(row[acc_col_orig]):\n",
    "                        acc_raw = str(row[acc_col_orig]).strip()\n",
    "                        acc = re.sub(r'[\\s\\-]', '', acc_raw) # Remove spaces and hyphens\n",
    "                        if acc: account_numbers.add(acc) # Add cleaned version\n",
    "                    \n",
    "                    if meter_col_orig and pd.notna(row[meter_col_orig]):\n",
    "                        mtr = str(row[meter_col_orig]).strip()\n",
    "                        # Basic validation for meter numbers\n",
    "                        if mtr and len(mtr) > 2 and any(c.isalnum() for c in mtr): \n",
    "                            # Avoid adding if it's an exact duplicate of an already found account number\n",
    "                            # (sometimes meter is listed as account)\n",
    "                            cleaned_mtr_for_comp = re.sub(r'[\\s\\-]', '', mtr)\n",
    "                            if cleaned_mtr_for_comp not in account_numbers:\n",
    "                                meter_numbers.add(mtr)\n",
    "                    \n",
    "                    if rate_class_col_orig and pd.notna(row[rate_class_col_orig]):\n",
    "                        rc = str(row[rate_class_col_orig]).strip()\n",
    "                        if rc and len(rc) < 25 and \"price\" not in rc.lower() and \"$\" not in rc and \"¢\" not in rc and \"agreement\" not in rc.lower():\n",
    "                            rate_classes.add(rc)\n",
    "                except KeyError: continue\n",
    "                except Exception: continue \n",
    "    \n",
    "    # --- Text-Based Fallback Extraction ---\n",
    "    full_text_search_space = \"\\n\".join(sections.values()) if sections else markdown_content_for_fallback # Use full_markdown_text if sections empty\n",
    "\n",
    "    if not service_addresses:\n",
    "        addr_patterns = [\n",
    "            re.compile(r\"(?:Facility Address|Service Address|Physical Business Address)\\s*[:\\-]?\\s*(.+)\", re.IGNORECASE)\n",
    "        ]\n",
    "        for pattern in addr_patterns:\n",
    "            for match in pattern.finditer(full_text_search_space):\n",
    "                addr = match.group(1).split('\\n')[0].strip()\n",
    "                if addr and len(addr) > 5: service_addresses.add(addr); break\n",
    "            if service_addresses: break \n",
    "    \n",
    "    if not account_numbers:\n",
    "        acc_patterns = [\n",
    "            re.compile(r\"(?:Account Number\\(s\\)|Account No|Utility Account Number|ACCOUNT NUMBER)\\s*\\(?[^)]*\\)?\\s*[:\\-]?\\s*([\\w\\-\\s]+)\", re.IGNORECASE)\n",
    "        ]\n",
    "        for pattern in acc_patterns:\n",
    "            for match in pattern.finditer(full_text_search_space):\n",
    "                acc_raw = match.group(1).strip()\n",
    "                acc = re.sub(r'[\\s\\-]', '', acc_raw)\n",
    "                if acc: account_numbers.add(acc); break\n",
    "            if account_numbers: break\n",
    "            \n",
    "    if not meter_numbers:\n",
    "        meter_patterns = [ re.compile(r\"Meter\\s*#\\s*[:\\-]?\\s*([\\w\\-\\s\\/]+)\", re.IGNORECASE) ]\n",
    "        for pattern in meter_patterns:\n",
    "            for match in pattern.finditer(full_text_search_space):\n",
    "                mtr = match.group(1).strip()\n",
    "                if mtr and len(mtr) > 1 and mtr.lower() != \"facility(ies)\" and not mtr.lower().startswith(\"attached exhibit\"): \n",
    "                     # Check if it might be an account number already found\n",
    "                    cleaned_mtr_for_comp = re.sub(r'[\\s\\-]', '', mtr)\n",
    "                    if cleaned_mtr_for_comp not in account_numbers:\n",
    "                        meter_numbers.add(mtr)\n",
    "                        break \n",
    "            if meter_numbers: break\n",
    "\n",
    "    # Rate class from text is harder, tables are primary. Can add patterns if needed.\n",
    "\n",
    "    contract_data_dict['service_addresses'] = sorted(list(service_addresses))\n",
    "    contract_data_dict['account_numbers'] = sorted(list(account_numbers))\n",
    "    contract_data_dict['meter_numbers'] = sorted(list(meter_numbers))\n",
    "    \n",
    "    rc_list = sorted(list(rate_classes))\n",
    "    if len(rc_list) == 1: contract_data_dict['rate_class'] = rc_list[0]\n",
    "    elif len(rc_list) > 1: contract_data_dict['rate_class'] = rc_list\n",
    "    else: contract_data_dict['rate_class'] = None\n",
    "        \n",
    "    # Print summary\n",
    "    # if service_addresses: print(f\"    Details: Found {len(service_addresses)} service address(es).\")\n",
    "    # if account_numbers: print(f\"    Details: Found {len(account_numbers)} account number(s).\")\n",
    "    # if meter_numbers: print(f\"    Details: Found {len(meter_numbers)} meter number(s).\")\n",
    "    # if rate_classes: print(f\"    Details: Found {len(rate_classes)} rate class(es).\")\n",
    "    if not any([service_addresses, account_numbers, meter_numbers, rate_classes]):\n",
    "        notes.append(\"No service/account details found.\")\n",
    "        # print(\"    Details: No service/account details found.\")\n",
    "\n",
    "    contract_data_dict['_notes'] = notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "4ccac1aa-bea0-4f0f-8c49-289185714226",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_party_and_governing_law(sections, tables, contract_data_dict, full_markdown_text):\n",
    "    \"\"\"\n",
    "    Extracts Seller Name, Buyer Name (Customer), and Governing Law/State.\n",
    "    Populates relevant fields in contract_data_dict.\n",
    "    \"\"\"\n",
    "    notes = contract_data_dict.get(\"_notes\", [])\n",
    "    \n",
    "    seller_name = None\n",
    "    buyer_name = None # This could be legal entity or DBA\n",
    "    governing_law_state = None\n",
    "\n",
    "    # --- Search Space ---\n",
    "    # Preamble often at the start of the document, not necessarily in a specific \"section\" if H2s start later.\n",
    "    # Signature blocks are often at the end.\n",
    "    # Governing law clause might be its own section or within a general terms section.\n",
    "\n",
    "    # Use full_markdown_text for broader searches, and sections for targeted ones.\n",
    "    # Try to identify specific sections first\n",
    "    \n",
    "    notice_section_text = None\n",
    "    governing_law_section_text = None\n",
    "    preamble_text = full_markdown_text[:2000] # Approx first 2000 chars for preamble\n",
    "\n",
    "    for section_name, section_content in sections.items():\n",
    "        if \"notices\" in section_name.lower():\n",
    "            notice_section_text = section_content\n",
    "        elif \"governing law\" in section_name.lower() or \"applicable law\" in section_name.lower():\n",
    "            governing_law_section_text = section_content\n",
    "        # Signature sections are harder to name consistently, often just \"SELLER:\", \"BUYER:\"\n",
    "        # We'll rely on full_markdown_text for those if not in a specific \"Signatures\" section.\n",
    "\n",
    "    # --- Seller and Buyer Name Extraction ---\n",
    "    # Priority: Look near \"SELLER:\" and \"BUYER:\" labels, often in Notices or signature areas.\n",
    "    # Regex: SELLER:\\s*([A-Za-z0-9 .,&()IncLLC]+)\n",
    "    \n",
    "    # Pattern to capture text after \"SELLER:\" or \"BUYER Name:\" up to newline or common terminators\n",
    "    # Ex1: Seller, Tiger, Inc. | BUYER Name: Barcelona Rino LLC\n",
    "    # Ex2: Business Name (legal contracting entity): barcelona waypointe llc\n",
    "    # Ex4: Customer Name: Barcelona Wine Bar\n",
    "    \n",
    "    seller_patterns = [\n",
    "        re.compile(r\"Seller\\s*[,:]\\s*(?P<name>[A-Za-z0-9\\s.,&()IncLLC]+?)(?:,?\\s*agrees|\\n|hereby)\", re.IGNORECASE), # \"Seller, Tiger, Inc., agrees\" or \"Seller: Name\"\n",
    "        re.compile(r\"\\bSELLER\\s*:\\s*(?P<name>[A-Z0-9\\s.,&()INCLLC]+)(?:\\n|Suite J\\.|Attn:)\", re.MULTILINE), # All caps seller\n",
    "        re.compile(r\"between\\s+(?P<name>[A-Za-z0-9\\s.,&()IncLLC]+?)\\s+\\(\\s*[\\\"\\']Seller[\\\"\\']\\s*\\)\", re.IGNORECASE) # \"between Company (Seller)\"\n",
    "    ]\n",
    "    buyer_patterns = [\n",
    "        re.compile(r\"Buyer\\s*[,:]\\s*(?P<name>[A-Za-z0-9\\s.,&()IncLLC]+?)(?:,?\\s*agrees|\\n|Facility Address:)\", re.IGNORECASE),\n",
    "        re.compile(r\"\\bBUYER Name\\s*:\\s*(?P<name>[A-Za-z0-9\\s.,&()IncLLC]+)\", re.IGNORECASE),\n",
    "        re.compile(r\"(?:Customer Name|Business Name.*?):\\s*(?P<name>[A-Za-z0-9\\s.,&()IncLLC]+)\", re.IGNORECASE), # Ex2, Ex4\n",
    "        re.compile(r\"and\\s+(?P<name>[A-Za-z0-9\\s.,&()IncLLC]+?)\\s+\\(\\s*[\\\"\\']Buyer[\\\"\\']\\s*\\)\", re.IGNORECASE), # \"and Company (Buyer)\"\n",
    "        re.compile(r\"\\bBUYER\\s*:\\s*(?P<name>[A-Z0-9\\s.,&()INCLLC]+)(?:\\n|By:)\", re.MULTILINE) # All caps buyer\n",
    "    ]\n",
    "\n",
    "    search_areas_for_parties = [preamble_text]\n",
    "    if notice_section_text: search_areas_for_parties.append(notice_section_text)\n",
    "    search_areas_for_parties.append(full_markdown_text[-2000:]) # Last 2000 chars for signatures\n",
    "\n",
    "    for text_block in search_areas_for_parties:\n",
    "        if not seller_name:\n",
    "            for pattern in seller_patterns:\n",
    "                match = pattern.search(text_block)\n",
    "                if match:\n",
    "                    name_cand = match.group(\"name\").strip().rstrip(',')\n",
    "                    # Avoid overly short or generic matches like \"Seller\" itself if it's not followed by more\n",
    "                    if len(name_cand) > 6 or \"Inc\" in name_cand or \"LLC\" in name_cand:\n",
    "                        seller_name = name_cand\n",
    "                        print(f\"    Parties: Found Seller Name: {seller_name}\")\n",
    "                        break\n",
    "        if not buyer_name:\n",
    "            for pattern in buyer_patterns:\n",
    "                match = pattern.search(text_block)\n",
    "                if match:\n",
    "                    name_cand = match.group(\"name\").strip().rstrip(',')\n",
    "                    if len(name_cand) > 6 or \"Inc\" in name_cand or \"LLC\" in name_cand or \"barcelona\" in name_cand.lower(): # barcelona is specific to examples\n",
    "                        buyer_name = name_cand\n",
    "                        print(f\"    Parties: Found Buyer Name: {buyer_name}\")\n",
    "                        break\n",
    "        if seller_name and buyer_name:\n",
    "            break\n",
    "\n",
    "    # --- Governing Law Extraction ---\n",
    "    # Ex1: This contract shall be governed by the laws of the State of Colorado.\n",
    "    # Ex2: This Agreement shall be governed by the laws of the State of Texas\n",
    "    gov_law_pattern = re.compile(r\"governed by the laws of the State of\\s+([A-Za-z\\s]+)\\.?\", re.IGNORECASE)\n",
    "    \n",
    "    search_areas_for_law = []\n",
    "    if governing_law_section_text:\n",
    "        search_areas_for_law.append(governing_law_section_text)\n",
    "        print(\"    GovLaw: Searching in dedicated Governing Law section.\")\n",
    "    search_areas_for_law.append(full_markdown_text) # Search full doc as fallback\n",
    "\n",
    "    for text_block in search_areas_for_law:\n",
    "        match = gov_law_pattern.search(text_block)\n",
    "        if match:\n",
    "            governing_law_state = match.group(1).strip()\n",
    "            print(f\"    GovLaw: Found Governing Law State: {governing_law_state}\")\n",
    "            break # Found it\n",
    "\n",
    "    # Update contract_data_dict\n",
    "    contract_data_dict['seller_name'] = seller_name\n",
    "    contract_data_dict['buyer_name'] = buyer_name # Could be 'customer_name'\n",
    "    contract_data_dict['governing_law_state'] = governing_law_state\n",
    "\n",
    "    if not seller_name: notes.append(\"Seller name not found.\")\n",
    "    if not buyer_name: notes.append(\"Buyer/Customer name not found.\")\n",
    "    if not governing_law_state: notes.append(\"Governing law/state not found.\")\n",
    "    \n",
    "    contract_data_dict['_notes'] = notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "id": "dc2bc6b1-8106-40ae-a669-cbce6ae4bec4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching for contract folders in: /Users/josephndigiovanni/Downloads/UChicago/SP24/Capstone 1/outputs\n",
      "\n",
      "Processing: Example 2 (Contract)/Example 2 (Contract).md\n",
      "  Successfully read 30822 characters from Example 2 (Contract).md.\n",
      "  Found 13 refined sections: ['CUSTOMER INFORMATION', 'CONTRACT INFORMATION', 'ACKNOWLEDGMENT AND CONSENT', 'FACILITIES/ACCOUNTS', 'SECTION 1. TERMS OF SERVICE', 'SECTION 2. GENERAL TERMS AND CONDITIONS', 'SECTION 3. DEFINITIONS', 'Service Options', 'Customer Information and Authorization', 'Requestor & Billing Information', 'Additional Locations', 'Supplier/Consultant Information (please print):', 'Operating Company Information (please print):']\n",
      "  Found 8 tables (via HTML parsing).\n",
      "    Table 0 columns: ['Field', 'Details']\n",
      "    Table 1 columns: ['Signature', 'Customer', 'ENGIE']\n",
      "    Table 2 columns: ['NO.', 'FACILITY NAME/ SERVICE ADDRESS', 'CITY, STATE, ZIP', 'UTILITY', 'DELIVERY POINT', 'ACCOUNT NUMBER']\n",
      "    Table 3 columns: ['1.BA 51823187091', 'SA 211953002', '6.BA', 'SA']\n",
      "    Table 4 columns: ['Utility', 'Utility Account #', 'Service Address']\n",
      "    Table 5 columns: ['NO.', 'FACILITY NAME/ SERVICE ADDRESS', 'CITY, STATE, ZIP', 'UTILITY', 'DELIVERY POINT', 'ACCOUNT NUMBER']\n",
      "    Table 6 columns: ['NO.', 'FACILITY NAME/ SERVICE ADDRESS', 'CITY, STATE, ZIP', 'UTILITY', 'DELIVERY POINT', 'ACCOUNT NUMBER']\n",
      "    Table 7 columns: ['NO.', 'FACILITY NAME/ SERVICE ADDRESS', 'CITY, STATE, ZIP', 'UTILITY', 'DELIVERY POINT', 'ACCOUNT NUMBER']\n",
      "  Duration: Searching in 'SECTION 1. TERMS OF SERVICE' section.\n",
      "  Duration: Searching in 'CONTRACT INFORMATION' section.\n",
      "    Start Date found: 2022-11-01\n",
      "    End Date found: 2026-10-31\n",
      "  Rates: Using section 'CONTRACT INFORMATION' for rates search.\n",
      "  Rates: Using section 'SECTION 1. TERMS OF SERVICE' for rates search.\n",
      "  Rates: Using section 'SECTION 2. GENERAL TERMS AND CONDITIONS' for rates search.\n",
      "  Rates: Using section 'SECTION 3. DEFINITIONS' for rates search.\n",
      "  Rates: Using section 'Service Options' for rates search.\n",
      "\n",
      "DEBUG HELPER MATCH (Target Contract/Section: 'Example 2 (Contract)'/'CONTRACT INFORMATION'):\n",
      "  Line Matched by Regex: '- **Contract price ($/kwh):** 0.09623'\n",
      "  Iterating over groups for this match:\n",
      "    Group (tier_prefix): ''\n",
      "    Group (label): 'Contract price'\n",
      "    Group (currency_in_label): '$'\n",
      "    Group (unit_in_label): 'kwh'\n",
      "    Group (description_before_math): '**'\n",
      "    Group (math_operator): 'None'\n",
      "    Group (currency_before_value): 'None'\n",
      "    Group (value): '0.09623'\n",
      "    Group (unit_after_value): 'None'\n",
      "    Group (unit_val_in_paren): 'None'\n",
      "--- End of Groups for this Match ---\n",
      "    Found Rate (single_general_pattern): 0.09623 $/KWH\n",
      "  Usage: Analyzing Table 0 with columns: ['Field', 'Details']\n",
      "  Usage: Analyzing Table 1 with columns: ['Signature', 'Customer', 'ENGIE']\n",
      "  Usage: Analyzing Table 2 with columns: ['NO.', 'FACILITY NAME/ SERVICE ADDRESS', 'CITY, STATE, ZIP', 'UTILITY', 'DELIVERY POINT', 'ACCOUNT NUMBER']\n",
      "  Usage: Analyzing Table 3 with columns: ['1.BA 51823187091', 'SA 211953002', '6.BA', 'SA']\n",
      "  Usage: Analyzing Table 4 with columns: ['Utility', 'Utility Account #', 'Service Address']\n",
      "  Usage: Analyzing Table 5 with columns: ['NO.', 'FACILITY NAME/ SERVICE ADDRESS', 'CITY, STATE, ZIP', 'UTILITY', 'DELIVERY POINT', 'ACCOUNT NUMBER']\n",
      "  Usage: Analyzing Table 6 with columns: ['NO.', 'FACILITY NAME/ SERVICE ADDRESS', 'CITY, STATE, ZIP', 'UTILITY', 'DELIVERY POINT', 'ACCOUNT NUMBER']\n",
      "  Usage: Analyzing Table 7 with columns: ['NO.', 'FACILITY NAME/ SERVICE ADDRESS', 'CITY, STATE, ZIP', 'UTILITY', 'DELIVERY POINT', 'ACCOUNT NUMBER']\n",
      "    Usage: No monthly usage table identified.\n",
      "    Usage: No monthly table data. Checking for Annual Usage fallback.\n",
      "    Details: Processing Table 2 for account/service info (Cols: A:FACILITY NAME/ SERVICE ADDRESS, Acct:ACCOUNT NUMBER, M:DELIVERY POINT, RC:None).\n",
      "    Details: Processing Table 4 for account/service info (Cols: A:Service Address, Acct:None, M:None, RC:None).\n",
      "    Details: Processing Table 5 for account/service info (Cols: A:FACILITY NAME/ SERVICE ADDRESS, Acct:ACCOUNT NUMBER, M:DELIVERY POINT, RC:None).\n",
      "    Details: Processing Table 6 for account/service info (Cols: A:FACILITY NAME/ SERVICE ADDRESS, Acct:ACCOUNT NUMBER, M:DELIVERY POINT, RC:None).\n",
      "    Details: Processing Table 7 for account/service info (Cols: A:FACILITY NAME/ SERVICE ADDRESS, Acct:ACCOUNT NUMBER, M:DELIVERY POINT, RC:None).\n",
      "    GovLaw: Found Governing Law State: Texas\n",
      "\n",
      "--- Summary for Example 2 (Contract) ---\n",
      "  Contract Id: Example 2 (Contract)\n",
      "  Seller Name: None\n",
      "  Buyer Name: None\n",
      "  Governing Law State: Texas\n",
      "  Contract Duration: {'start_date': '2022-11-01', 'end_date': '2026-10-31'}\n",
      "  Monthly Forecasted Usage: {}\n",
      "  Contracted Rates: [{'rate': '0.09623', 'unit_full_string': '$/KWH', 'base_unit': 'KWH', 'label_matched': 'Contract price'}]\n",
      "  Unit Of Measurement: KWH\n",
      "  Rate Class: None\n",
      "  Service Addresses: ['515 West Ave Ph 5 Str 5 Norwalk, CT 06850']\n",
      "  Account Numbers: ['211953002.0']\n",
      "  Meter Numbers: ['51823187091.0']\n",
      "   Current Section Name Debug: Service Options\n",
      "  Notes: ['No table found with recognizable month and usage columns.', 'Seller name not found.', 'Buyer/Customer name not found.']\n",
      "--- End Summary ---\n",
      "  Warning: No .md file found in Example 3 (Contract)\n",
      "\n",
      "Processing: Example 1 (Contract)/Example 1 (Contract).md\n",
      "  Successfully read 17353 characters from Example 1 (Contract).md.\n",
      "  Found 21 refined sections: ['1. Nature of Service', '2. Term', '3. Quantity', '4. Price', '5. Delivery Point', '6. Quantity and Measurement', '7. Warranty of Title', '8. Billing and Payment', '9. Force Majeure', '10. Assignment', '11. Governing Laws', '12. Taxes', '13. Liability', '14. Notices', 'SELLER', 'BUYER', 'Contract Price', 'Delivery Period', 'Performance Obligation and Contract Quantity', 'Delivery Point(s)', 'Special Conditions']\n",
      "  Found 7 tables (via HTML parsing).\n",
      "    Table 0 columns: ['BANK:', 'BANK OF OKLAHOMA']\n",
      "    Table 1 columns: ['Attention:', 'Jody Sommers']\n",
      "    Table 2 columns: [\"Seller's Signature\", 'Unnamed: 1']\n",
      "    Table 3 columns: [\"Buyer's Signature\", 'Jody Sommers']\n",
      "    Table 4 columns: ['Month', 'Volume']\n",
      "    Table 5 columns: ['Name', 'Title', 'Phone Number']\n",
      "    Table 6 columns: ['Receiving Party', 'Agent Shipper']\n",
      "  Duration: Searching in 'Delivery Period' section.\n",
      "  Duration: Searching in '2. Term' section.\n",
      "    Start Date found: 2022-04-01\n",
      "    End Date found: 2025-03-31\n",
      "  Rates: Using section 'Contract Price' for rates search.\n",
      "\n",
      "[EX1 DEBUG] Processing Section 'Contract Price' line by line for rates.\n",
      "  [EX1 L1] Attempting match on: '- **Tier One:** Fixed Price: $4.40 per Dth (April 1, 2022 - March 31, 2025)'\n",
      "  [EX1 L2] Attempting match on: '- **Tier Two:** Index Price: Gas Market Report - Colorado Interstate Gas + $.99 per Dth'\n",
      "  [EX1 L4] Attempting match on: 'Plus all transport costs on Public Service and the upstream transporter including fuel loss, service and facility charges, firming capacity charges, transport charges and/or applicable sales taxes and/or franchise fees.'\n",
      "  Rates: Warning: No contracted rates found for Example 1 (Contract).\n",
      "  Usage: Analyzing Table 0 with columns: ['BANK:', 'BANK OF OKLAHOMA']\n",
      "  Usage: Analyzing Table 1 with columns: ['Attention:', 'Jody Sommers']\n",
      "  Usage: Analyzing Table 2 with columns: [\"Seller's Signature\", 'Unnamed: 1']\n",
      "  Usage: Analyzing Table 3 with columns: [\"Buyer's Signature\", 'Jody Sommers']\n",
      "  Usage: Analyzing Table 4 with columns: ['Month', 'Volume']\n",
      "    Usage: Found potential usage table 4 (Cols: 'Month', 'Volume')\n",
      "      Raw usage added: Month 1, Value 150\n",
      "      Raw usage added: Month 2, Value 150\n",
      "      Raw usage added: Month 3, Value 150\n",
      "      Raw usage added: Month 4, Value 115\n",
      "      Raw usage added: Month 5, Value 110\n",
      "      Raw usage added: Month 6, Value 100\n",
      "      Raw usage added: Month 7, Value 100\n",
      "      Raw usage added: Month 8, Value 90\n",
      "      Raw usage added: Month 9, Value 85\n",
      "      Raw usage added: Month 10, Value 100\n",
      "      Raw usage added: Month 11, Value 120\n",
      "      Raw usage added: Month 12, Value 140\n",
      "    Usage: Using a 12-month usage pattern from table(s).\n",
      "    Usage: Assigned usage for 36 months.\n",
      "    Parties: Found Seller Name: Tiger, Inc.\n",
      "    GovLaw: Searching in dedicated Governing Law section.\n",
      "    GovLaw: Found Governing Law State: Colorado\n",
      "\n",
      "--- Summary for Example 1 (Contract) ---\n",
      "  Contract Id: Example 1 (Contract)\n",
      "  Seller Name: Tiger, Inc.\n",
      "  Buyer Name: None\n",
      "  Governing Law State: Colorado\n",
      "  Contract Duration: {'start_date': '2022-04-01', 'end_date': '2025-03-31'}\n",
      "  Monthly Forecasted Usage: {'2022-04': 150, '2022-05': 150, '2022-06': 150, '2022-07': 115, '2022-08': 110, '2022-09': 100, '2022-10': 100, '2022-11': 90, '2022-12': 85, '2023-01': 100, '2023-02': 120, '2023-03': 140, '2023-04': 150, '2023-05': 150, '2023-06': 150, '2023-07': 115, '2023-08': 110, '2023-09': 100, '2023-10': 100, '2023-11': 90, '2023-12': 85, '2024-01': 100, '2024-02': 120, '2024-03': 140, '2024-04': 150, '2024-05': 150, '2024-06': 150, '2024-07': 115, '2024-08': 110, '2024-09': 100, '2024-10': 100, '2024-11': 90, '2024-12': 85, '2025-01': 100, '2025-02': 120, '2025-03': 140}\n",
      "  Contracted Rates: []\n",
      "  Unit Of Measurement: MMBTU\n",
      "  Rate Class: None\n",
      "  Service Addresses: ['2900 Larimer St']\n",
      "  Account Numbers: []\n",
      "  Meter Numbers: ['When Buyer exceeds its baseload volume on a monthly basis']\n",
      "   Current Section Name Debug: Contract Price\n",
      "  Notes: [\"UoM 'MMBTU' from 'GAS' keyword.\", 'No contracted rate information found.', 'Applied 12-month usage pattern over contract duration.', 'Buyer/Customer name not found.']\n",
      "--- End Summary ---\n",
      "\n",
      "Processing: Example 4 (Contract)/Example 4 (Contract).md\n",
      "  Successfully read 39333 characters from Example 4 (Contract).md.\n",
      "  Found 34 refined sections: ['Customer Information', 'Natural Gas Transaction Confirmation', 'Service Locations', 'Delivery Period', 'Delivery Point', 'Contract Quantity (MMBTU)', 'Purchase Price', 'Special Provisions', 'Tax Exemption Status - If exempt, must attach certificate', 'CUSTOMER INFORMATION', 'NATURAL GAS TRANSACTION CONFIRMATION', 'SERVICE LOCATIONS', 'DELIVERY PERIOD', 'DELIVERY POINT', 'CONTRACT QUANTITY (MMBTU)', 'PURCHASE PRICE', 'SPECIAL PROVISIONS', 'TAX EXEMPTION STATUS - If exempt, must attach certificate', '1. Transactions', '2. Performance', '3. Term', '4. Purchase Price', '5. Changes to Purchase Price', '6. Billing and Payment', '7. Taxes', '8. Disputes', '9. Title and Risk of Loss', '10. Material Deviation', '11. Force Majeure', '12. Financial Responsibility', 'Default', 'Remedies', 'Representations, Warranties, and Covenants', 'Confidentiality']\n",
      "  Found 13 tables (via HTML parsing).\n",
      "    Table 0 columns: ['Service Address', 'Utility Account Number', 'Rate']\n",
      "    Table 1 columns: ['Unnamed: 0', 'Monthly']\n",
      "    Table 2 columns: ['New', 'Renew']\n",
      "    Table 3 columns: ['Service Address', 'Utility Account Number', 'Rate']\n",
      "    Table 4 columns: ['Month', 'Monthly Quantity']\n",
      "    Table 5 columns: ['Buyer: Barcelona Wine Bar', 'Seller: Direct Energy Business Marketing, LLC']\n",
      "    Table 6 columns: ['Service Address', 'Utility Account Number', 'Rate']\n",
      "    Table 7 columns: ['Month', 'Quantity']\n",
      "    Table 8 columns: ['New', 'Renew']\n",
      "    Table 9 columns: ['Service Address', 'Utility Account Number', 'Rate']\n",
      "    Table 10 columns: ['Unnamed: 0', 'Unnamed: 1', 'Unnamed: 2']\n",
      "    Table 11 columns: ['Buyer:', 'Barcelona Wine Bar', 'Seller:', 'Direct Energy Business Marketing, LLC']\n",
      "    Table 12 columns: ['Buyer: Barcelona Wine Bar', 'Seller: Direct Energy Business, LLC / Direct Energy Business Marketing, LLC']\n",
      "  Duration: Searching in 'Delivery Period' section.\n",
      "  Duration: Searching in '3. Term' section.\n",
      "    Start Date found: 2022-02-01\n",
      "    End Date found: 2026-01-31\n",
      "  Rates: Using section 'Purchase Price' for rates search.\n",
      "  Rates: Using section 'PURCHASE PRICE' for rates search.\n",
      "  Rates: Using section '4. Purchase Price' for rates search.\n",
      "  Rates: Using section '5. Changes to Purchase Price' for rates search.\n",
      "    Found Rate (single_general_pattern): 6.898 $/MMBTU\n",
      "  Usage: Analyzing Table 0 with columns: ['Service Address', 'Utility Account Number', 'Rate']\n",
      "  Usage: Analyzing Table 1 with columns: ['Unnamed: 0', 'Monthly']\n",
      "  Usage: Analyzing Table 2 with columns: ['New', 'Renew']\n",
      "  Usage: Analyzing Table 3 with columns: ['Service Address', 'Utility Account Number', 'Rate']\n",
      "  Usage: Analyzing Table 4 with columns: ['Month', 'Monthly Quantity']\n",
      "    Usage: Found potential usage table 4 (Cols: 'Month', 'Monthly Quantity')\n",
      "      Raw usage added: Month 2, Value 336\n",
      "      Raw usage added: Month 3, Value 257\n",
      "      Raw usage added: Month 4, Value 216\n",
      "      Raw usage added: Month 5, Value 79\n",
      "      Raw usage added: Month 6, Value 53\n",
      "      Raw usage added: Month 7, Value 49\n",
      "      Raw usage added: Month 8, Value 49\n",
      "      Raw usage added: Month 9, Value 57\n",
      "      Raw usage added: Month 10, Value 149\n",
      "      Raw usage added: Month 11, Value 241\n",
      "      Raw usage added: Month 12, Value 330\n",
      "      Raw usage added: Month 1, Value 354\n",
      "    Usage: Using a 12-month usage pattern from table(s).\n",
      "    Usage: Assigned usage for 48 months.\n",
      "    Details: Processing Table 0 for account/service info (Cols: A:Service Address, Acct:Utility Account Number, M:None, RC:Rate).\n",
      "    Details: Processing Table 3 for account/service info (Cols: A:Service Address, Acct:Utility Account Number, M:None, RC:Rate).\n",
      "    Details: Processing Table 6 for account/service info (Cols: A:Service Address, Acct:Utility Account Number, M:None, RC:Rate).\n",
      "    Details: Processing Table 9 for account/service info (Cols: A:Service Address, Acct:Utility Account Number, M:None, RC:Rate).\n",
      "\n",
      "--- Summary for Example 4 (Contract) ---\n",
      "  Contract Id: Example 4 (Contract)\n",
      "  Seller Name: None\n",
      "  Buyer Name: None\n",
      "  Governing Law State: None\n",
      "  Contract Duration: {'start_date': '2022-02-01', 'end_date': '2026-01-31'}\n",
      "  Monthly Forecasted Usage: {'2022-02': 354, '2022-03': 336, '2022-04': 257, '2022-05': 216, '2022-06': 79, '2022-07': 53, '2022-08': 49, '2022-09': 49, '2022-10': 57, '2022-11': 149, '2022-12': 241, '2023-01': 330, '2023-02': 354, '2023-03': 336, '2023-04': 257, '2023-05': 216, '2023-06': 79, '2023-07': 53, '2023-08': 49, '2023-09': 49, '2023-10': 57, '2023-11': 149, '2023-12': 241, '2024-01': 330, '2024-02': 354, '2024-03': 336, '2024-04': 257, '2024-05': 216, '2024-06': 79, '2024-07': 53, '2024-08': 49, '2024-09': 49, '2024-10': 57, '2024-11': 149, '2024-12': 241, '2025-01': 330, '2025-02': 354, '2025-03': 336, '2025-04': 257, '2025-05': 216, '2025-06': 79, '2025-07': 53, '2025-08': 49, '2025-09': 49, '2025-10': 57, '2025-11': 149, '2025-12': 241, '2026-01': 330}\n",
      "  Contracted Rates: [{'rate': '6.898', 'unit_full_string': '$/MMBTU', 'base_unit': 'MMBTU', 'label_matched': 'Fixed Price'}]\n",
      "  Unit Of Measurement: MMBTU\n",
      "  Rate Class: ['10', '20', 'FIRM']\n",
      "  Service Addresses: ['155 Temple St', '222 Summer St.', '222 Summer St. Suite 1', '4180 Black Rock Tpke', '515 West Ave.', '971 Farmington Ave']\n",
      "  Account Numbers: ['1802080190000457868', '40000000293213', '4734050090000649828', '5000000113222', '5000000126549', '5590150780000533430']\n",
      "  Meter Numbers: []\n",
      "   Current Section Name Debug: 5. Changes to Purchase Price\n",
      "  Notes: ['Applied 12-month usage pattern over contract duration.', 'Seller name not found.', 'Buyer/Customer name not found.', 'Governing law/state not found.']\n",
      "--- End Summary ---\n",
      "\n",
      "--- Processed 3 contract files. ---\n",
      "Successfully saved summary to /Users/josephndigiovanni/Downloads/UChicago/SP24/Capstone 1/outputs/hybrid_json_outputs/hybrid_summary.json\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    all_extracted_data = []\n",
    "    file_count = 0\n",
    "\n",
    "    for md_file_path in find_contract_files(BASE_OUTPUT_DIR):\n",
    "        print(f\"\\nProcessing: {md_file_path.parent.name}/{md_file_path.name}\")\n",
    "        file_count += 1\n",
    "        \n",
    "        markdown_content = read_markdown_file(md_file_path)\n",
    "        if not markdown_content:\n",
    "            continue\n",
    "\n",
    "        contract_id = md_file_path.parent.name\n",
    "        current_contract_data = {\n",
    "            \"contract_id\": contract_id,\n",
    "            \"_source_file\": str(md_file_path.relative_to(BASE_OUTPUT_DIR)),\n",
    "            \"_notes\": [],\n",
    "            \"seller_name\": None, # New\n",
    "            \"buyer_name\": None,  # New\n",
    "            \"governing_law_state\": None, #New\n",
    "            \"contract_duration\": {\"start_date\": None, \"end_date\": None},\n",
    "            \"monthly_forecasted_usage\": {},\n",
    "            \"contracted_rates\": [],\n",
    "            \"unit_of_measurement\": None,\n",
    "            \"rate_class\": None, \n",
    "            \"service_addresses\": [],\n",
    "            \"account_numbers\": [],\n",
    "            \"meter_numbers\": []\n",
    "        }\n",
    "\n",
    "        parsed_structure = parse_markdown_to_structured_data(markdown_content)\n",
    "        sections = parsed_structure.get(\"sections\", {})\n",
    "        tables = parsed_structure.get(\"tables\", [])\n",
    "        \n",
    "        print(f\"  Found {len(sections)} refined sections: {list(sections.keys())}\")\n",
    "        if tables:\n",
    "            print(f\"  Found {len(tables)} tables (via HTML parsing).\")\n",
    "            for idx, table_df in enumerate(tables):\n",
    "                print(f\"    Table {idx} columns: {table_df.columns.tolist()}\")\n",
    "        else:\n",
    "            print(\"  No tables found by HTML parsing.\")\n",
    "\n",
    "        # --- Call Extraction Functions ---\n",
    "        extract_contract_duration(sections, tables, current_contract_data)\n",
    "        extract_rates_and_unit(sections, tables, current_contract_data, markdown_content) \n",
    "        extract_monthly_usage(sections, tables, current_contract_data)\n",
    "        extract_service_account_details(sections, tables, current_contract_data, markdown_content) \n",
    "        extract_party_and_governing_law(sections, tables, current_contract_data, markdown_content)\n",
    "        \n",
    "        # --- Print Summary of Extracted Data for this Contract ---\n",
    "        print(f\"\\n--- Summary for {contract_id} ---\")\n",
    "        for key, value in current_contract_data.items():\n",
    "            if key != \"_notes\" and key != \"_source_file\": # Don't print internal keys here\n",
    "                 print(f\"  {key.replace('_', ' ').title()}: {value}\")\n",
    "        if current_contract_data[\"_notes\"]:\n",
    "            print(f\"  Notes: {current_contract_data['_notes']}\")\n",
    "        print(\"--- End Summary ---\")\n",
    "\n",
    "        all_extracted_data.append(current_contract_data)\n",
    "\n",
    "    print(f\"\\n--- Processed {file_count} contract files. ---\")\n",
    "\n",
    "    if all_extracted_data:\n",
    "        output_summary_file = JSON_OUTPUT_DIR / \"hybrid_summary.json\"\n",
    "        try:\n",
    "            with open(output_summary_file, 'w', encoding='utf-8') as f:\n",
    "                json.dump(all_extracted_data, f, indent=2, ensure_ascii=False)\n",
    "            print(f\"Successfully saved summary to {output_summary_file}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error saving summary file: {e}\")\n",
    "    else:\n",
    "        print(\"No data extracted to save.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
