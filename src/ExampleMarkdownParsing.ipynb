{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "206db467-fc6e-4664-b381-7b994dce1d41",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "from pathlib import Path\n",
    "import re # Import regex module for later use\n",
    "\n",
    "# Define the base directory where the example folders are located\n",
    "BASE_OUTPUT_DIR = Path(\"/Users/josephndigiovanni/Downloads/UChicago/SP24/Capstone 1/outputs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d688b552-21b7-4573-83b6-6459a61fa1c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List to hold the results for all contracts\n",
    "all_contract_data = []\n",
    "\n",
    "def process_contracts(base_dir):\n",
    "    \"\"\"\n",
    "    Finds, reads, and prepares to process contract markdown files.\n",
    "    \"\"\"\n",
    "    print(f\"Searching for contract folders in: {base_dir.resolve()}\")\n",
    "\n",
    "    # Iterate through items in the base directory\n",
    "    for item in base_dir.iterdir():\n",
    "        # Check if it's a directory and seems like an example folder\n",
    "        # (Adjust the naming check if needed)\n",
    "        if item.is_dir() and '(Contract)' in item.name:\n",
    "            contract_folder = item\n",
    "            print(f\"\\nFound contract folder: {contract_folder.name}\")\n",
    "\n",
    "            # --- Find the markdown file ---\n",
    "            md_files = list(contract_folder.glob('*.md'))\n",
    "\n",
    "            if not md_files:\n",
    "                print(f\"  Warning: No .md file found in {contract_folder.name}\")\n",
    "                continue\n",
    "            elif len(md_files) > 1:\n",
    "                print(f\"  Warning: Multiple .md files found in {contract_folder.name}. Using the first one: {md_files[0].name}\")\n",
    "\n",
    "            md_file_path = md_files[0]\n",
    "            print(f\"  Processing markdown file: {md_file_path.name}\")\n",
    "\n",
    "            # --- Read the markdown content ---\n",
    "            try:\n",
    "                with open(md_file_path, 'r', encoding='utf-8') as f:\n",
    "                    markdown_content = f.read()\n",
    "                # print(f\"  Successfully read {len(markdown_content)} characters.\")\n",
    "                # Limit printing content for brevity during development\n",
    "                # print(\"-\" * 20 + \" Start Content Sample \" + \"-\" * 20)\n",
    "                # print(markdown_content[:500] + \"...\") # Print first 500 chars\n",
    "                # print(\"-\" * 20 + \" End Content Sample \" + \"-\" * 20)\n",
    "\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"  Error reading file {md_file_path}: {e}\")\n",
    "                continue\n",
    "\n",
    "            # --- Prepare data structure ---\n",
    "            # Use the folder name (or part of it) as a preliminary contract ID\n",
    "            contract_id = contract_folder.name # Or derive a cleaner ID if needed\n",
    "\n",
    "            contract_data = {\n",
    "                \"contract_id\": contract_id,\n",
    "                \"customer_dba_name\": None,\n",
    "                \"service_addresses\": [],\n",
    "                \"account_numbers\": [],\n",
    "                \"meter_numbers\": [],\n",
    "                \"contract_duration\": {\"start_date\": None, \"end_date\": None},\n",
    "                \"rate_class\": None,\n",
    "                \"contracted_rates\": [],\n",
    "                \"unit_of_measurement\": None,\n",
    "                \"monthly_forecasted_usage\": {},\n",
    "                \"_source_file\": str(md_file_path.relative_to(base_dir)) # Keep track of source\n",
    "            }\n",
    "\n",
    "            # --- Placeholder for future extraction steps ---\n",
    "            # extract_data(markdown_content, contract_data) # We'll build this function\n",
    "\n",
    "            all_contract_data.append(contract_data)\n",
    "            print(f\"  Prepared basic structure for contract: {contract_id}\")\n",
    "\n",
    "    return all_contract_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f82bcfda-64e8-430e-b4f4-6ea6cda8cb66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching for contract folders in: /Users/josephndigiovanni/Downloads/UChicago/SP24/Capstone 1/outputs\n",
      "\n",
      "Found contract folder: Example 2 (Contract)\n",
      "  Processing markdown file: Example 2 (Contract).md\n",
      "  Prepared basic structure for contract: Example 2 (Contract)\n",
      "\n",
      "Found contract folder: Example 3 (Contract)\n",
      "  Warning: No .md file found in Example 3 (Contract)\n",
      "\n",
      "Found contract folder: Example 1 (Contract)\n",
      "  Processing markdown file: Example 1 (Contract).md\n",
      "  Prepared basic structure for contract: Example 1 (Contract)\n",
      "\n",
      "Found contract folder: Example 4 (Contract)\n",
      "  Processing markdown file: Example 4 (Contract).md\n",
      "  Prepared basic structure for contract: Example 4 (Contract)\n",
      "\n",
      "Processed 3 contract folders.\n"
     ]
    }
   ],
   "source": [
    "# --- Main execution ---\n",
    "if __name__ == \"__main__\":\n",
    "    if not BASE_OUTPUT_DIR.exists():\n",
    "        print(f\"Error: Base directory '{BASE_OUTPUT_DIR}' does not exist.\")\n",
    "    else:\n",
    "        extracted_data_list = process_contracts(BASE_OUTPUT_DIR)\n",
    "        print(f\"\\nProcessed {len(extracted_data_list)} contract folders.\")\n",
    "\n",
    "        # Optional: Print the basic structures created\n",
    "        # for data in extracted_data_list:\n",
    "        #     print(json.dumps(data, indent=2))\n",
    "\n",
    "        # Next steps will involve populating the fields in 'contract_data'\n",
    "        # by parsing 'markdown_content'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b7cfa34c-71fd-4ea3-9908-067b6c72b186",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching for contract folders in: /Users/josephndigiovanni/Downloads/UChicago/SP24/Capstone 1/outputs\n",
      "\n",
      "Found contract folder: Example 2 (Contract)\n",
      "  Processing markdown file: Example 2 (Contract).md\n",
      "  Successfully read 30822 characters.\n",
      "  Contract duration pattern not found.\n",
      "\n",
      "Found contract folder: Example 3 (Contract)\n",
      "  Warning: No .md file found in Example 3 (Contract)\n",
      "\n",
      "Found contract folder: Example 1 (Contract)\n",
      "  Processing markdown file: Example 1 (Contract).md\n",
      "  Successfully read 17353 characters.\n",
      "  Contract duration pattern not found.\n",
      "\n",
      "Found contract folder: Example 4 (Contract)\n",
      "  Processing markdown file: Example 4 (Contract).md\n",
      "  Successfully read 39333 characters.\n",
      "  Contract duration pattern not found.\n",
      "\n",
      "Processed 3 contract files.\n",
      "\n",
      "Successfully saved summary to /Users/josephndigiovanni/Downloads/UChicago/SP24/Capstone 1/outputs/extracted_contracts_summary.json\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "from dateutil.relativedelta import relativedelta # For adding months to dates\n",
    "import pandas as pd # Using pandas for robust date parsing\n",
    "\n",
    "def normalize_date(date_str):\n",
    "    \"\"\"Attempts to parse a date string into YYYY-MM-DD format.\"\"\"\n",
    "    if not date_str:\n",
    "        return None\n",
    "    try:\n",
    "        # Use pandas to_datetime which is flexible with formats\n",
    "        dt = pd.to_datetime(date_str)\n",
    "        return dt.strftime('%Y-%m-%d')\n",
    "    except (ValueError, TypeError):\n",
    "        print(f\"  Warning: Could not parse date: {date_str}\")\n",
    "        return None\n",
    "\n",
    "def calculate_end_date(start_date_str, months):\n",
    "    \"\"\"Calculates end date given start date string and number of months.\"\"\"\n",
    "    start_date = pd.to_datetime(start_date_str)\n",
    "    # Subtract one day from the date after adding months to get the last day of the period\n",
    "    end_date = start_date + relativedelta(months=months) - relativedelta(days=1)\n",
    "    return end_date.strftime('%Y-%m-%d')\n",
    "\n",
    "\n",
    "def extract_contract_duration(markdown_content, contract_data):\n",
    "    \"\"\"\n",
    "    Extracts the contract start and end dates from markdown content.\n",
    "    \"\"\"\n",
    "    start_date = None\n",
    "    end_date = None\n",
    "    months = None\n",
    "\n",
    "    # --- Regex Patterns ---\n",
    "    # Pattern 1: Explicit Start and End Dates (various formats)\n",
    "    # Covers \"Begin: MM/DD/YYYY End: MM/DD/YYYY\", \"Start Date: ... End Date: ...\", etc.\n",
    "    pattern1 = re.compile(\n",
    "        r\"(?:Begin|Start Date|Effective Date|Start)\\s*[:\\-]?\\s*([\\d/.-]+|\\w+\\s\\d{1,2},\\s\\d{4})\\s*\"\n",
    "        r\"(?:End|End Date)\\s*[:\\-]?\\s*([\\d/.-]+|\\w+\\s\\d{1,2},\\s\\d{4})\",\n",
    "        re.IGNORECASE\n",
    "    )\n",
    "\n",
    "    # Pattern 2: Delivery Period Keyword (similar structure)\n",
    "    pattern2 = re.compile(\n",
    "        r\"Delivery Period\\s*[:\\-]?\\s*Begin\\s*[:\\-]?\\s*([\\d/.-]+|\\w+\\s\\d{1,2},\\s\\d{4})\\s*\"\n",
    "        r\"End\\s*[:\\-]?\\s*([\\d/.-]+|\\w+\\s\\d{1,2},\\s\\d{4})\",\n",
    "        re.IGNORECASE\n",
    "    )\n",
    "\n",
    "    # Pattern 3: \"term of XX Months\" potentially near a start date\n",
    "    pattern3_term = re.compile(r\"term of\\s+(\\d+)\\s+Months\", re.IGNORECASE)\n",
    "    pattern3_start = re.compile(\n",
    "        r\"(?:on or after|effective|starting|Begin)\\s*[:\\-]?\\s*([\\d/.-]+|\\w+\\s\\d{1,2},\\s\\d{4})\",\n",
    "        re.IGNORECASE\n",
    "    )\n",
    "\n",
    "    # Pattern 4: Specific structure from Example 3 Contract doc (page 39)\n",
    "    pattern4 = re.compile(r\"on or after\\s+([\\w\\s\\d,]+)\\s+and will continue for a term of\\s+(\\d+)\\s+Months\", re.IGNORECASE)\n",
    "\n",
    "    # Pattern 5: Specific structure from Example 4 Contract doc (page 21)\n",
    "    pattern5 = re.compile(r\"DELIVERY PERIOD\\s+Begin\\s*[:\\-]?\\s*([\\d/.-]+)\\s+End\\s*[:\\-]?\\s*([\\d/.-]+)\", re.IGNORECASE)\n",
    "\n",
    "\n",
    "    # --- Search using patterns ---\n",
    "    match = pattern1.search(markdown_content)\n",
    "    if not match:\n",
    "        match = pattern2.search(markdown_content)\n",
    "    if not match:\n",
    "        match = pattern5.search(markdown_content) # Check specific pattern 5\n",
    "\n",
    "    if match:\n",
    "        start_date = normalize_date(match.group(1).strip())\n",
    "        end_date = normalize_date(match.group(2).strip())\n",
    "        print(f\"  Duration Found (Pattern 1/2/5): Start={start_date}, End={end_date}\")\n",
    "    else:\n",
    "        # Try pattern 4\n",
    "        match4 = pattern4.search(markdown_content)\n",
    "        if match4:\n",
    "            start_date = normalize_date(match4.group(1).strip())\n",
    "            months = int(match4.group(2))\n",
    "            print(f\"  Duration Found (Pattern 4): Start={start_date}, Months={months}\")\n",
    "        else:\n",
    "            # Try pattern 3 (Term + Separate Start Date) - search near term\n",
    "            match3_term = pattern3_term.search(markdown_content)\n",
    "            if match3_term:\n",
    "                months = int(match3_term.group(1))\n",
    "                # Search for start date within a reasonable range around the term match\n",
    "                search_range = markdown_content[max(0, match3_term.start() - 100):match3_term.end() + 100]\n",
    "                match3_start = pattern3_start.search(search_range)\n",
    "                if match3_start:\n",
    "                    start_date = normalize_date(match3_start.group(1).strip())\n",
    "                    print(f\"  Duration Found (Pattern 3): Start={start_date}, Months={months}\")\n",
    "                else:\n",
    "                    print(f\"  Duration Found (Pattern 3): Months={months}, but Start Date not found nearby.\")\n",
    "            else:\n",
    "                 print(\"  Contract duration pattern not found.\")\n",
    "\n",
    "\n",
    "    # --- Calculate End Date if only Start and Months are found ---\n",
    "    if start_date and months and not end_date:\n",
    "        try:\n",
    "            end_date = calculate_end_date(start_date, months)\n",
    "            print(f\"  Calculated End Date: {end_date}\")\n",
    "        except Exception as e:\n",
    "            print(f\"  Warning: Could not calculate end date from start {start_date} and {months} months: {e}\")\n",
    "\n",
    "\n",
    "    # --- Update contract_data ---\n",
    "    if start_date or end_date:\n",
    "        contract_data['contract_duration']['start_date'] = start_date\n",
    "        contract_data['contract_duration']['end_date'] = end_date\n",
    "    elif months:\n",
    "         # Store months if dates are missing, maybe add a note\n",
    "         contract_data['contract_duration']['duration_months'] = months\n",
    "         print(f\"  Stored duration in months: {months}\")\n",
    "\n",
    "\n",
    "# (Keep the process_contracts function from the previous step, but add the call)\n",
    "\n",
    "def process_contracts(base_dir):\n",
    "    \"\"\"\n",
    "    Finds, reads, and processes contract markdown files.\n",
    "    \"\"\"\n",
    "    print(f\"Searching for contract folders in: {base_dir.resolve()}\")\n",
    "    processed_files_count = 0\n",
    "\n",
    "    # Iterate through items in the base directory\n",
    "    for item in base_dir.iterdir():\n",
    "        # Check if it's a directory and seems like an example folder\n",
    "        if item.is_dir() and '(Contract)' in item.name:\n",
    "            contract_folder = item\n",
    "            print(f\"\\nFound contract folder: {contract_folder.name}\")\n",
    "\n",
    "            # --- Find the markdown file ---\n",
    "            md_files = list(contract_folder.glob('*.md'))\n",
    "\n",
    "            if not md_files:\n",
    "                print(f\"  Warning: No .md file found in {contract_folder.name}\")\n",
    "                continue\n",
    "            elif len(md_files) > 1:\n",
    "                print(f\"  Warning: Multiple .md files found in {contract_folder.name}. Using the first one: {md_files[0].name}\")\n",
    "\n",
    "            md_file_path = md_files[0]\n",
    "            print(f\"  Processing markdown file: {md_file_path.name}\")\n",
    "\n",
    "            # --- Read the markdown content ---\n",
    "            try:\n",
    "                with open(md_file_path, 'r', encoding='utf-8') as f:\n",
    "                    markdown_content = f.read()\n",
    "                if not markdown_content.strip(): # Check if file is empty\n",
    "                     print(\"  Warning: Markdown file is empty.\")\n",
    "                     # Still create a basic entry, but don't try to parse\n",
    "                     contract_id = contract_folder.name\n",
    "                     contract_data = {\n",
    "                         \"contract_id\": contract_id,\n",
    "                         \"customer_dba_name\": None, # Initialize all fields\n",
    "                         \"service_addresses\": [],\n",
    "                         \"account_numbers\": [],\n",
    "                         \"meter_numbers\": [],\n",
    "                         \"contract_duration\": {\"start_date\": None, \"end_date\": None},\n",
    "                         \"rate_class\": None,\n",
    "                         \"contracted_rates\": [],\n",
    "                         \"unit_of_measurement\": None,\n",
    "                         \"monthly_forecasted_usage\": {},\n",
    "                         \"_source_file\": str(md_file_path.relative_to(base_dir)),\n",
    "                         \"_notes\": [\"Markdown file was empty or whitespace only\"]\n",
    "                     }\n",
    "                     all_contract_data.append(contract_data)\n",
    "                     processed_files_count += 1\n",
    "                     continue # Skip to next folder\n",
    "\n",
    "                print(f\"  Successfully read {len(markdown_content)} characters.\")\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"  Error reading file {md_file_path}: {e}\")\n",
    "                continue\n",
    "\n",
    "            # --- Prepare data structure ---\n",
    "            contract_id = contract_folder.name\n",
    "            contract_data = {\n",
    "                \"contract_id\": contract_id,\n",
    "                \"customer_dba_name\": None,\n",
    "                \"service_addresses\": [],\n",
    "                \"account_numbers\": [],\n",
    "                \"meter_numbers\": [],\n",
    "                \"contract_duration\": {\"start_date\": None, \"end_date\": None},\n",
    "                \"rate_class\": None,\n",
    "                \"contracted_rates\": [],\n",
    "                \"unit_of_measurement\": None,\n",
    "                \"monthly_forecasted_usage\": {},\n",
    "                 \"_source_file\": str(md_file_path.relative_to(base_dir)),\n",
    "                 \"_notes\": [] # Add a list for potential notes\n",
    "            }\n",
    "\n",
    "            # --- Extract data ---\n",
    "            extract_contract_duration(markdown_content, contract_data)\n",
    "            # Add calls to other extraction functions here later\n",
    "            # extract_usage_forecast(markdown_content, contract_data)\n",
    "            # extract_unit_and_rate(markdown_content, contract_data)\n",
    "            # ... etc\n",
    "\n",
    "            all_contract_data.append(contract_data)\n",
    "            processed_files_count += 1\n",
    "            # print(f\"  Updated structure for contract: {contract_id}\")\n",
    "            # print(json.dumps(contract_data['contract_duration'], indent=2))\n",
    "\n",
    "\n",
    "    print(f\"\\nProcessed {processed_files_count} contract files.\")\n",
    "    return all_contract_data\n",
    "\n",
    "# --- Main execution ---\n",
    "if __name__ == \"__main__\":\n",
    "    if not BASE_OUTPUT_DIR.exists():\n",
    "        print(f\"Error: Base directory '{BASE_OUTPUT_DIR}' does not exist.\")\n",
    "    else:\n",
    "        extracted_data_list = process_contracts(BASE_OUTPUT_DIR)\n",
    "\n",
    "        # Optional: Print the final list of extracted data\n",
    "        # print(\"\\n--- Final Extracted Data ---\")\n",
    "        # print(json.dumps(extracted_data_list, indent=2))\n",
    "\n",
    "        # Save to a JSON file\n",
    "        output_file = BASE_OUTPUT_DIR / \"extracted_contracts_summary.json\"\n",
    "        try:\n",
    "            with open(output_file, 'w', encoding='utf-8') as f:\n",
    "                json.dump(extracted_data_list, f, indent=2, ensure_ascii=False)\n",
    "            print(f\"\\nSuccessfully saved summary to {output_file}\")\n",
    "        except Exception as e:\n",
    "            print(f\"\\nError saving summary file: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5166545a-fdca-40a3-9785-87833424c9ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import calendar\n",
    "\n",
    "def generate_year_month_keys(start_date_str, end_date_str):\n",
    "    \"\"\"Generates a list of 'YYYY-MM' keys between start and end dates.\"\"\"\n",
    "    keys = []\n",
    "    try:\n",
    "        start_date = pd.to_datetime(start_date_str)\n",
    "        end_date = pd.to_datetime(end_date_str)\n",
    "        current_date = start_date\n",
    "        while current_date <= end_date:\n",
    "            keys.append(current_date.strftime('%Y-%m'))\n",
    "            # Move to the first day of the next month\n",
    "            current_date = (current_date.replace(day=1) + relativedelta(months=1))\n",
    "        # Handle edge case where duration might be very short or dates are weird\n",
    "        if start_date.strftime('%Y-%m') not in keys and start_date <= end_date:\n",
    "             keys.insert(0, start_date.strftime('%Y-%m'))\n",
    "        if end_date.strftime('%Y-%m') not in keys and start_date <= end_date:\n",
    "             # Only add if the month hasn't already been advanced past\n",
    "             last_key_date = pd.to_datetime(keys[-1]+'-01') if keys else start_date.replace(day=1) - relativedelta(months=1)\n",
    "             if end_date >= last_key_date + relativedelta(months=1):\n",
    "                  keys.append(end_date.strftime('%Y-%m'))\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"  Warning: Could not generate date keys from {start_date_str} to {end_date_str}: {e}\")\n",
    "    return keys\n",
    "\n",
    "def map_month_name_to_number(month_name):\n",
    "    \"\"\"Converts month name (e.g., 'Jan', 'January') to month number (1-12).\"\"\"\n",
    "    month_name = month_name.strip().lower()[:3]\n",
    "    month_map = {name.lower()[:3]: num for num, name in enumerate(calendar.month_abbr) if num > 0}\n",
    "    return month_map.get(month_name)\n",
    "\n",
    "# Assume normalize_date, calculate_end_date, pandas (pd), re, etc. are available\n",
    "\n",
    "\n",
    "def extract_usage_forecast(markdown_content, contract_data):\n",
    "    \"\"\"\n",
    "    Extracts the monthly forecasted usage data, focusing on table structures\n",
    "    and validating matches. Relies on contract_duration being populated.\n",
    "    \"\"\"\n",
    "    usage_data = defaultdict(int)\n",
    "    monthly_values_raw = [] # Store tuples of (month_num, value) or (year_month_str, value)\n",
    "    found_monthly_data = False\n",
    "    notes = contract_data.get(\"_notes\", [])\n",
    "\n",
    "    # --- Section Identification (Optional but recommended for large docs) ---\n",
    "    # Look for lines indicating start of usage sections\n",
    "    usage_section_headers = [\n",
    "        \"Performance Obligation\",\n",
    "        \"Contract Quantity\",\n",
    "        \"Monthly Quantity\",\n",
    "        \"Baseload Volume per Month\" # Added from Example 1\n",
    "    ]\n",
    "    # Find lines containing these headers (case-insensitive)\n",
    "    section_starts = []\n",
    "    for header in usage_section_headers:\n",
    "        try:\n",
    "            # Find all occurrences, store line number or index\n",
    "             for match in re.finditer(rf\"^\\s*\\#*.*{re.escape(header)}.*$\", markdown_content, re.IGNORECASE | re.MULTILINE):\n",
    "                 section_starts.append(match.start())\n",
    "        except re.error as e:\n",
    "            print(f\"  Regex error looking for header '{header}': {e}\")\n",
    "            continue # Skip header if regex is invalid\n",
    "\n",
    "    search_text = markdown_content # Default to searching whole document\n",
    "\n",
    "    # If sections found, we could potentially narrow down search_text,\n",
    "    # but parsing blocks accurately can be complex. For now, we'll just use\n",
    "    # the header presence as a stronger indicator later.\n",
    "    if section_starts:\n",
    "        print(f\"  Identified potential usage section header(s): {usage_section_headers}\")\n",
    "    else:\n",
    "        print(\"  No specific usage section headers found, searching document.\")\n",
    "\n",
    "\n",
    "    # --- Revised Regex Patterns (Stricter Table Focus) ---\n",
    "    month_pattern_str = r\"(?P<month>Jan(?:uary)?|Feb(?:ruary)?|Mar(?:ch)?|Apr(?:il)?|May|Jun(?:e)?|Jul(?:y)?|Aug(?:ust)?|Sep(?:tember)?|Oct(?:ober)?|Nov(?:ember)?|Dec(?:ember)?)\"\n",
    "    # Value pattern: integer, allowing commas\n",
    "    value_pattern_str = r\"(?P<value>[\\d,]+)\"\n",
    "\n",
    "    # Pattern 1: Explicit Markdown Table Row | Month | Value |\n",
    "    # Requires pipes, allows optional spacing.\n",
    "    table_row_pattern_month_first = re.compile(\n",
    "        r\"^\\s*\\|\\s*\" + month_pattern_str + r\"\\s*\\|\\s*\" + value_pattern_str + r\"\\s*\\|.*$\",\n",
    "        re.IGNORECASE | re.MULTILINE\n",
    "    )\n",
    "    # Pattern 2: Explicit Markdown Table Row | Value | Month |\n",
    "    table_row_pattern_value_first = re.compile(\n",
    "        r\"^\\s*\\|\\s*\" + value_pattern_str + r\"\\s*\\|\\s*\" + month_pattern_str + r\"\\s*\\|.*$\",\n",
    "        re.IGNORECASE | re.MULTILINE\n",
    "    )\n",
    "    # Pattern 3: Less strict, potentially space-separated, but month MUST be followed by number relatively closely\n",
    "    # Looks for MonthName followed by space(s) then Number, typical in simpler lists/tables\n",
    "    # This is riskier, use carefully\n",
    "    spaced_pattern_month_first = re.compile(\n",
    "        r\"^\\s*\" + month_pattern_str + r\"\\s+\" + value_pattern_str + r\"\\s*$\", # Anchored start/end\n",
    "        re.IGNORECASE | re.MULTILINE\n",
    "    )\n",
    "\n",
    "\n",
    "    # --- Search for Usage Data using refined patterns ---\n",
    "    all_matches = []\n",
    "    all_matches.extend(table_row_pattern_month_first.finditer(search_text))\n",
    "    all_matches.extend(table_row_pattern_value_first.finditer(search_text))\n",
    "    # Only add spaced pattern if pipe patterns found nothing or very little\n",
    "    if not all_matches:\n",
    "         print(\"  Pipe table pattern yielded no results, trying spaced pattern (less reliable).\")\n",
    "         all_matches.extend(spaced_pattern_month_first.finditer(search_text))\n",
    "\n",
    "    processed_matches_count = 0\n",
    "    for match in all_matches:\n",
    "        month_name = match.group(\"month\")\n",
    "        value_str = match.group(\"value\").replace(',', '')\n",
    "\n",
    "        # --- VALIDATION ---\n",
    "        month_num = map_month_name_to_number(month_name)\n",
    "        value = None\n",
    "        if month_num:\n",
    "            try:\n",
    "                value = int(value_str)\n",
    "            except (ValueError, TypeError):\n",
    "                # Value is not a valid integer, ignore this match\n",
    "                # print(f\"  Debug: Invalid value '{value_str}' for month '{month_name}' in match: {match.group(0)}\") # Debug line\n",
    "                continue # Skip to next match\n",
    "\n",
    "        if month_num and value is not None:\n",
    "            # Valid match found!\n",
    "            monthly_values_raw.append((month_num, value))\n",
    "            found_monthly_data = True\n",
    "            processed_matches_count += 1\n",
    "            # print(f\"  Validated usage: {month_name} ({month_num}) -> {value}\") # Debug line\n",
    "        #else:\n",
    "            # print(f\"  Debug: Invalid month '{month_name}' or value '{value_str}' in match: {match.group(0)}\") # Debug line\n",
    "\n",
    "\n",
    "    print(f\"  Found {processed_matches_count} potential & validated monthly usage data points.\")\n",
    "\n",
    "    # --- Process Found Data (Logic remains similar, but now uses validated data) ---\n",
    "    if found_monthly_data:\n",
    "        print(\"  Processing validated monthly usage data (assigning years).\")\n",
    "        start_date_str = contract_data['contract_duration'].get('start_date')\n",
    "        end_date_str = contract_data['contract_duration'].get('end_date')\n",
    "\n",
    "        if start_date_str and end_date_str:\n",
    "            all_keys = generate_year_month_keys(start_date_str, end_date_str)\n",
    "            if not all_keys:\n",
    "                 notes.append(\"Could not generate date keys for usage mapping despite having start/end dates.\")\n",
    "                 print(\"  Error: Could not generate date keys for usage mapping.\")\n",
    "            else:\n",
    "                month_to_value = defaultdict(int)\n",
    "                # Aggregate potentially multiple tables/locations\n",
    "                for m, v in monthly_values_raw:\n",
    "                    month_to_value[m] += v\n",
    "\n",
    "                num_unique_months_found = len(month_to_value)\n",
    "                print(f\"  Aggregated data for {num_unique_months_found} unique months.\")\n",
    "\n",
    "                if num_unique_months_found == 12:\n",
    "                    print(f\"  Applying 12-month usage pattern across {len(all_keys)} months.\")\n",
    "                    for key in all_keys:\n",
    "                        year, month_num = map(int, key.split('-'))\n",
    "                        usage_data[key] = month_to_value.get(month_num, 0)\n",
    "                elif num_unique_months_found > 0:\n",
    "                     # Determine sequence based on actual found month numbers\n",
    "                     month_sequence = sorted(month_to_value.keys())\n",
    "                     values_in_order = [month_to_value[m] for m in month_sequence]\n",
    "\n",
    "                     print(f\"  Mapping found {num_unique_months_found} months cyclically across {len(all_keys)} month duration.\")\n",
    "                     notes.append(f\"Applied pattern for {num_unique_months_found} months over {len(all_keys)} month duration (cyclical if needed).\")\n",
    "                     if len(all_keys) > 0 and num_unique_months_found > 0:\n",
    "                        for i, key in enumerate(all_keys):\n",
    "                            usage_data[key] = values_in_order[i % num_unique_months_found] # Cycle through found values\n",
    "                     else:\n",
    "                           notes.append(f\"Cannot apply cyclical pattern: num_keys={len(all_keys)}, num_months={num_unique_months_found}\")\n",
    "\n",
    "                else: # num_unique_months_found == 0\n",
    "                    notes.append(\"Validated matches, but resulted in 0 unique months of data.\")\n",
    "                    print(\"  Warning: Validated matches, but resulted in 0 unique months.\")\n",
    "\n",
    "        else:\n",
    "            notes.append(\"Cannot map monthly usage without contract start/end dates.\")\n",
    "            print(\"  Warning: Cannot assign years to monthly usage without contract start/end dates.\")\n",
    "\n",
    "    # --- Handle Annual Usage (Fallback - Logic remains the same) ---\n",
    "    if not found_monthly_data:\n",
    "        print(\"  No monthly usage table found. Checking for annual usage...\")\n",
    "        # (Keep the annual usage pattern search logic from before)\n",
    "        annual_pattern = re.compile(r\"Annual\\s+(?:Historical\\s+)?Usage\\s*(?:\\(.*\\))?\\s*[:\\-]?\\s*([\\d,]+)\", re.IGNORECASE)\n",
    "        annual_match = annual_pattern.search(markdown_content)\n",
    "        if annual_match:\n",
    "            try:\n",
    "                annual_value = int(annual_match.group(1).replace(',', ''))\n",
    "                monthly_estimate = round(annual_value / 12)\n",
    "                print(f\"  Found Annual Usage: {annual_value}. Estimating monthly as: {monthly_estimate}\")\n",
    "\n",
    "                start_date_str = contract_data['contract_duration'].get('start_date')\n",
    "                end_date_str = contract_data['contract_duration'].get('end_date')\n",
    "\n",
    "                if start_date_str and end_date_str:\n",
    "                    all_keys = generate_year_month_keys(start_date_str, end_date_str)\n",
    "                    if all_keys:\n",
    "                        for key in all_keys:\n",
    "                            usage_data[key] = monthly_estimate\n",
    "                        notes.append(f\"Estimated monthly usage ({monthly_estimate}) from annual total ({annual_value}).\")\n",
    "                    else:\n",
    "                         notes.append(f\"Found annual usage ({annual_value}) but could not generate date keys to distribute.\")\n",
    "                else:\n",
    "                    notes.append(f\"Found annual usage ({annual_value}) but cannot distribute without contract start/end dates.\")\n",
    "\n",
    "            except ValueError:\n",
    "                print(f\"  Warning: Could not parse annual usage value: {annual_match.group(1)}\")\n",
    "            except Exception as e:\n",
    "                print(f\"  Error processing annual usage: {e}\")\n",
    "        else:\n",
    "            print(\"  No annual usage value found either.\")\n",
    "            notes.append(\"No monthly or annual usage data found.\")\n",
    "\n",
    "    # --- Final Update ---\n",
    "    contract_data['monthly_forecasted_usage'] = dict(sorted(usage_data.items())) # Sort by YYYY-MM\n",
    "    contract_data['_notes'] = notes\n",
    "\n",
    "\n",
    "# Assume other necessary imports and helper functions are available\n",
    "\n",
    "# Assume other necessary imports and helper functions are available\n",
    "\n",
    "def extract_unit_and_rate(markdown_content, contract_data):\n",
    "    \"\"\"\n",
    "    Extracts the contracted rate(s) and the primary unit of measurement.\n",
    "    Revised pattern for better markdown handling.\n",
    "    \"\"\"\n",
    "    rates = []\n",
    "    unit = None\n",
    "    notes = contract_data.get(\"_notes\", [])\n",
    "\n",
    "    # --- Revised Regex Patterns ---\n",
    "\n",
    "    # Pattern 1: Handle labels like **Fixed Price**:, Contract price ($/kwh): etc.\n",
    "    # More specific units, allows optional markdown **, flexible spacing, named groups\n",
    "    rate_pattern_markdown = re.compile(\n",
    "        r\"\\*{0,2}(?:Contract price|Fixed Price)\\*{0,2}\\s*[:\\-(]?\\s*\" # Label with optional **, :, -, or (\n",
    "        r\"(?P<currency>[\\$¢])?\"                                     # Optional currency symbol (Group 'currency')\n",
    "        r\"(?P<value>[\\d,]+(?:\\.\\d+)?)\"                              # Price value (Group 'value')\n",
    "        r\"\\s*(?:\\)?\\s*(?:per|\\/)\\s*)?\"                              # Optional closing ), separator per or / (optional)\n",
    "        r\"(?P<unit>KWh|MMBTU|Dth|Therm)\\b\",                         # Specific Unit (Group 'unit'), word boundary\n",
    "        re.IGNORECASE\n",
    "    )\n",
    "\n",
    "    # Pattern 2: Cents pattern (revised for flexibility)\n",
    "    cents_rate_pattern = re.compile(\n",
    "        r\"(?P<value>[\\d,]+(?:\\.\\d+)?)\\s+\\(?[Cc]ents?[\\/ ]KWh\\)?\", # Allow optional (), space or /\n",
    "        re.IGNORECASE\n",
    "    )\n",
    "\n",
    "    # Pattern 3: Unit context pattern (remains same, but add named group)\n",
    "    unit_context_pattern = re.compile(\n",
    "        r\"(?:Volume|Quantity)\\s+(?:per\\s+Month\\s+)?in\\s+(?P<unit>Dths|MMBTUs|kWh|Therms)\\b\",\n",
    "        re.IGNORECASE\n",
    "    )\n",
    "\n",
    "\n",
    "    # --- Search for Rate and Unit ---\n",
    "    found_rate = False\n",
    "    processed_matches = set() # Keep track of matched text to avoid duplicates from overlapping patterns\n",
    "\n",
    "    # Try Pattern 1\n",
    "    for match in rate_pattern_markdown.finditer(markdown_content):\n",
    "        match_text = match.group(0)\n",
    "        if match_text in processed_matches: continue # Skip if already processed\n",
    "        processed_matches.add(match_text)\n",
    "\n",
    "        price_str = match.group(\"value\").replace(',', '')\n",
    "        unit_str = match.group(\"unit\").upper()\n",
    "        currency_symbol = match.group(\"currency\")\n",
    "\n",
    "        # Basic unit standardization\n",
    "        if unit_str == \"DTHS\": unit_str = \"DTH\"\n",
    "        elif unit_str == \"THERMS\": unit_str = \"THERM\"\n",
    "        elif unit_str == \"MMBTUS\": unit_str = \"MMBTU\"\n",
    "        # KWH is fine\n",
    "\n",
    "        try:\n",
    "            price_val = float(price_str)\n",
    "            rate_unit_str = f\"$/{unit_str}\" # Default to dollars\n",
    "\n",
    "            if currency_symbol == '¢':\n",
    "                price_val = price_val / 100.0 # Convert cents to dollars\n",
    "                print(f\"  Found cents rate (pattern 1): {match.group('value')} {currency_symbol}/{unit_str} -> {price_val:.5f} $/ {unit_str}\")\n",
    "            else: # Assume dollars if $ or no symbol\n",
    "                 print(f\"  Found rate (pattern 1): {match.group('value')} {currency_symbol or '$'}/{unit_str}\")\n",
    "\n",
    "\n",
    "            rate_entry = {\n",
    "                \"rate\": f\"{price_val:.5f}\" if currency_symbol == '¢' else str(price_val), # Store consistently\n",
    "                \"unit\": rate_unit_str\n",
    "            }\n",
    "\n",
    "            # Avoid adding duplicate rates (same value and unit)\n",
    "            if rate_entry not in rates:\n",
    "                 rates.append(rate_entry)\n",
    "            if not unit: unit = unit_str # Assign first found unit as primary\n",
    "            found_rate = True\n",
    "\n",
    "        except ValueError:\n",
    "            print(f\"  Warning: Could not parse rate value: {match.group('value')}\")\n",
    "        except Exception as e:\n",
    "             print(f\"  Error processing rate match {match.group(0)}: {e}\")\n",
    "\n",
    "\n",
    "    # Try Pattern 2 (Cents pattern) only if Pattern 1 found nothing\n",
    "    if not found_rate:\n",
    "        for match in cents_rate_pattern.finditer(markdown_content):\n",
    "            match_text = match.group(0)\n",
    "            if match_text in processed_matches: continue\n",
    "            processed_matches.add(match_text)\n",
    "\n",
    "            price_str = match.group(\"value\").replace(',', '')\n",
    "            unit_str = \"KWH\" # Pattern implies kWh\n",
    "\n",
    "            try:\n",
    "                price_val_cents = float(price_str)\n",
    "                price_val_dollars = price_val_cents / 100.0\n",
    "                rate_entry = {\n",
    "                    \"rate\": f\"{price_val_dollars:.5f}\", # Store as dollar value string\n",
    "                    \"unit\": f\"$/{unit_str}\"\n",
    "                }\n",
    "                if rate_entry not in rates:\n",
    "                    rates.append(rate_entry)\n",
    "                if not unit: unit = unit_str\n",
    "                found_rate = True\n",
    "                print(f\"  Found cents rate (pattern 2): {price_val_cents} cents/KWh -> {price_val_dollars:.5f} $/KWH\")\n",
    "\n",
    "            except ValueError:\n",
    "                print(f\"  Warning: Could not parse cents rate value: {match.group('value')}\")\n",
    "            except Exception as e:\n",
    "                 print(f\"  Error processing cents rate match {match.group(0)}: {e}\")\n",
    "\n",
    "\n",
    "    # --- Determine Unit if not found via rate ---\n",
    "    if not unit:\n",
    "        print(\"  Unit not found with rate, checking context...\")\n",
    "        match = unit_context_pattern.search(markdown_content)\n",
    "        if match:\n",
    "            unit_str_context = match.group(\"unit\").upper()\n",
    "            # Standardize from context\n",
    "            if unit_str_context in [\"DTHS\", \"DTH\"]: unit = \"DTH\"\n",
    "            elif unit_str_context in [\"THERMS\"]: unit = \"THERM\"\n",
    "            elif unit_str_context == \"KWH\": unit = \"KWH\"\n",
    "            elif unit_str_context in [\"MMBTUS\", \"MMBTU\"]: unit = \"MMBTU\"\n",
    "\n",
    "            if unit:\n",
    "                 print(f\"  Found unit from context: {unit}\")\n",
    "                 notes.append(f\"Unit '{unit}' inferred from context (e.g., usage table header).\")\n",
    "            else:\n",
    "                 print(f\"  Found context unit '{match.group('unit')}' but couldn't standardize.\")\n",
    "                 notes.append(f\"Could not standardize unit '{match.group('unit')}' found from context.\")\n",
    "\n",
    "\n",
    "    # --- Final Unit Check and Notes ---\n",
    "    if not unit:\n",
    "        # Fallback inference based on keywords (keep this logic)\n",
    "        if \"ELECTRIC\" in markdown_content.upper():\n",
    "             unit = \"KWH\"\n",
    "             notes.append(\"Inferred unit KWH based on 'ELECTRIC' keyword in document.\")\n",
    "             print(\"  Inferred unit KWH based on 'ELECTRIC' keyword.\")\n",
    "        elif \"GAS\" in markdown_content.upper() or \"NATURAL GAS\" in markdown_content.upper():\n",
    "             unit = \"MMBTU\" # Default guess for gas based on Example 4\n",
    "             notes.append(\"Inferred unit MMBTU based on 'GAS' keyword in document (could be THERM/DTH).\")\n",
    "             print(\"  Inferred unit MMBTU based on 'GAS' keyword (could be THERM/DTH).\")\n",
    "        else:\n",
    "             notes.append(\"Could not determine unit of measurement.\")\n",
    "             print(\"  Warning: Could not determine unit of measurement.\")\n",
    "\n",
    "    if not rates:\n",
    "        notes.append(\"Could not find any contracted rate information.\")\n",
    "        print(\"  Warning: Could not find any contracted rate information.\")\n",
    "\n",
    "    # --- Update contract_data ---\n",
    "    contract_data['contracted_rates'] = rates\n",
    "    contract_data['unit_of_measurement'] = unit\n",
    "    contract_data['_notes'] = notes\n",
    "\n",
    "\n",
    "# --- process_contracts function remains the same ---\n",
    "# --- Main execution remains the same ---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "823b4d3b-c4ba-488b-8366-433aff638b80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching for contract folders in: /Users/josephndigiovanni/Downloads/UChicago/SP24/Capstone 1/outputs\n",
      "\n",
      "Found contract folder: Example 2 (Contract)\n",
      "  Processing markdown file: Example 2 (Contract).md\n",
      "  Successfully read 30822 characters.\n",
      "  Found Start Date: 2022-11-01 (using pattern: CONTRACT INFORMATION.*?\\n\\s*\\*{1,2}Start Date:\\*{1...)\n",
      "  Found End Date: 2026-10-31 (using pattern: CONTRACT INFORMATION.*?\\n\\s*\\*{1,2}End Date:\\*{1,2...)\n",
      "  No specific usage section headers found, searching document.\n",
      "  Pipe table pattern yielded no results, trying spaced pattern (less reliable).\n",
      "  Found 0 potential & validated monthly usage data points.\n",
      "  No monthly usage table found. Checking for annual usage...\n",
      "  No annual usage value found either.\n",
      "  Unit not found with rate, checking context...\n",
      "  Inferred unit KWH based on 'ELECTRIC' keyword.\n",
      "  Warning: Could not find any contracted rate information.\n",
      "\n",
      "Found contract folder: Example 3 (Contract)\n",
      "  Warning: No .md file found in Example 3 (Contract)\n",
      "\n",
      "Found contract folder: Example 1 (Contract)\n",
      "  Processing markdown file: Example 1 (Contract).md\n",
      "  Successfully read 17353 characters.\n",
      "  Found Start Date: 2022-04-01 (using pattern: Delivery Period\\s*\\n\\s*\\*{1,2}Begin:\\*{1,2}\\s+(?P<...)\n",
      "  Found End Date: 2025-03-31 (using pattern: Delivery Period\\s*\\n.*?\\*{1,2}End:\\*{1,2}\\s+(?P<da...)\n",
      "  Identified potential usage section header(s): ['Performance Obligation', 'Contract Quantity', 'Monthly Quantity', 'Baseload Volume per Month']\n",
      "  Found 12 potential & validated monthly usage data points.\n",
      "  Processing validated monthly usage data (assigning years).\n",
      "  Aggregated data for 12 unique months.\n",
      "  Applying 12-month usage pattern across 36 months.\n",
      "  Found rate (pattern 1): 4.40 $/DTH\n",
      "\n",
      "Found contract folder: Example 4 (Contract)\n",
      "  Processing markdown file: Example 4 (Contract).md\n",
      "  Successfully read 39333 characters.\n",
      "  Found Start Date: 2022-02-01 (using pattern: Delivery Period\\s*\\n\\s*\\*{1,2}Begin:\\*{1,2}\\s+(?P<...)\n",
      "  Found End Date: 2026-01-31 (using pattern: Delivery Period\\s*\\n.*?\\*{1,2}End:\\*{1,2}\\s+(?P<da...)\n",
      "  Identified potential usage section header(s): ['Performance Obligation', 'Contract Quantity', 'Monthly Quantity', 'Baseload Volume per Month']\n",
      "  Found 36 potential & validated monthly usage data points.\n",
      "  Processing validated monthly usage data (assigning years).\n",
      "  Aggregated data for 12 unique months.\n",
      "  Applying 12-month usage pattern across 48 months.\n",
      "  Found rate (pattern 1): 6.898 $/MMBTU\n",
      "\n",
      "Processed 3 contract files.\n",
      "\n",
      "Successfully saved summary to /Users/josephndigiovanni/Downloads/UChicago/SP24/Capstone 1/outputs/extracted_contracts_summary.json\n"
     ]
    }
   ],
   "source": [
    "# --- Update process_contracts to call the new function ---\n",
    "# (Make sure this call happens *after* extract_contract_duration)\n",
    "\n",
    "def process_contracts(base_dir):\n",
    "    \"\"\" Finds, reads, and processes contract markdown files. \"\"\"\n",
    "    print(f\"Searching for contract folders in: {base_dir.resolve()}\")\n",
    "    processed_files_count = 0\n",
    "    all_contract_data = [] # Initialize list here\n",
    "\n",
    "    for item in base_dir.iterdir():\n",
    "        if item.is_dir() and '(Contract)' in item.name:\n",
    "            contract_folder = item\n",
    "            print(f\"\\nFound contract folder: {contract_folder.name}\")\n",
    "            md_files = list(contract_folder.glob('*.md'))\n",
    "\n",
    "            if not md_files: # ... (handling for no/multiple md files)\n",
    "                print(f\"  Warning: No .md file found in {contract_folder.name}\")\n",
    "                continue\n",
    "            md_file_path = md_files[0]\n",
    "            print(f\"  Processing markdown file: {md_file_path.name}\")\n",
    "\n",
    "            try: # ... (reading file content)\n",
    "                 with open(md_file_path, 'r', encoding='utf-8') as f:\n",
    "                    markdown_content = f.read()\n",
    "                 if not markdown_content.strip():\n",
    "                     print(\"  Warning: Markdown file is empty.\")\n",
    "                     # Create basic entry\n",
    "                     contract_id = contract_folder.name\n",
    "                     contract_data = { # Initialize all fields\n",
    "                        \"contract_id\": contract_id,\"customer_dba_name\": None, \"service_addresses\": [], \"account_numbers\": [], \"meter_numbers\": [],\n",
    "                        \"contract_duration\": {\"start_date\": None, \"end_date\": None}, \"rate_class\": None, \"contracted_rates\": [],\n",
    "                        \"unit_of_measurement\": None, \"monthly_forecasted_usage\": {},\n",
    "                        \"_source_file\": str(md_file_path.relative_to(base_dir)), \"_notes\": [\"Markdown file was empty or whitespace only\"]\n",
    "                     }\n",
    "                     all_contract_data.append(contract_data)\n",
    "                     processed_files_count += 1\n",
    "                     continue\n",
    "                 print(f\"  Successfully read {len(markdown_content)} characters.\")\n",
    "            except Exception as e: # ... (error handling)\n",
    "                print(f\"  Error reading file {md_file_path}: {e}\")\n",
    "                continue\n",
    "\n",
    "            # --- Prepare data structure ---\n",
    "            contract_id = contract_folder.name\n",
    "            contract_data = { # Initialize all fields\n",
    "                \"contract_id\": contract_id,\"customer_dba_name\": None, \"service_addresses\": [], \"account_numbers\": [], \"meter_numbers\": [],\n",
    "                \"contract_duration\": {\"start_date\": None, \"end_date\": None}, \"rate_class\": None, \"contracted_rates\": [],\n",
    "                \"unit_of_measurement\": None, \"monthly_forecasted_usage\": {},\n",
    "                \"_source_file\": str(md_file_path.relative_to(base_dir)), \"_notes\": []\n",
    "            }\n",
    "\n",
    "            # --- Extract data (Duration first, then Usage) ---\n",
    "            extract_contract_duration(markdown_content, contract_data)\n",
    "            extract_usage_forecast(markdown_content, contract_data)\n",
    "            extract_unit_and_rate(markdown_content, contract_data) # <<< Added call\n",
    "            # ... add other extraction calls later\n",
    "\n",
    "            all_contract_data.append(contract_data)\n",
    "            processed_files_count += 1\n",
    "            # Optional: print details for debugging\n",
    "            # print(f\"  Forecast for {contract_id}: {contract_data['monthly_forecasted_usage']}\")\n",
    "            # print(f\"  Notes for {contract_id}: {contract_data['_notes']}\")\n",
    "\n",
    "\n",
    "    print(f\"\\nProcessed {processed_files_count} contract files.\")\n",
    "    return all_contract_data\n",
    "\n",
    "# --- Main execution (remains the same) ---\n",
    "if __name__ == \"__main__\":\n",
    "    if not BASE_OUTPUT_DIR.exists():\n",
    "        print(f\"Error: Base directory '{BASE_OUTPUT_DIR}' does not exist.\")\n",
    "    else:\n",
    "        extracted_data_list = process_contracts(BASE_OUTPUT_DIR)\n",
    "        output_file = BASE_OUTPUT_DIR / \"extracted_contracts_summary.json\"\n",
    "        try:\n",
    "            with open(output_file, 'w', encoding='utf-8') as f:\n",
    "                json.dump(extracted_data_list, f, indent=2, ensure_ascii=False)\n",
    "            print(f\"\\nSuccessfully saved summary to {output_file}\")\n",
    "        except Exception as e:\n",
    "            print(f\"\\nError saving summary file: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d89da3c9-827e-4a8d-af4a-f0b1d57331f3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
